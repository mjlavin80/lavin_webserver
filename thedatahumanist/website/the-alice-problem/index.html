<!doctype html>
<html>
<head>
<meta charset="utf-8">
<link type="text/css" rel="stylesheet" href="/static/dist/css/bootstrap.css" />
<link type="text/css" rel="stylesheet" href="/static/datahumanist.css" />
<title>The Alice Problem</title>
</head>
<body>
  <header>

      <div class="container header"><div class="row">
        <span id="logo" class="glyphicon glyphicon-download-alt"></span>
    <h1>The Data Humanist Website</h1>

</div>
</div>

<div class="container"><div class="row">
    <nav>
      <ul class="nav navbar-nav">
        <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/apps/">Web Apps</a></li>
        
          <li><a href="/feed.xml">Feed</a></li>
        
        <li>
          <a href="https://github.com/mjlavin80/the-data-humanist-jupyter-notebooks">Jupyter Notebooks</a></li>
        <li>
          <a href="http://humanitiesdata.com">Humanities Data</a></li>

      </ul>
    </nav>
</div>
</div>

  </header>
  <div class="container">
      <div class="row">
    
  
  <div class="blog-post">
    <div class="blog-body">
  
    <h2>The Alice Problem, or Something Clever Comparing Digital Humanities to a Rabbit Hole</h2>
  
  <p class="meta">
    Written By: 
      Matt Lavin
    
    <br/>
    Published On: December 15, 2016
  </p>

  <h3>The Conceit</h3><p>Not very long ago, one of my colleagues hired a programmer for his institution's digital humanities initiative. In advertising the position, he designed a set of three challenges designed to test candidates for baseline competency with programming as it might apply to the humanities. All three of the tasks were of the same sort and, honestly, I can only remember one of them.</p>
<p>It asked the candidate programmer to design a simple block of code, in any programming language, to return a list of the most frequent adjectives preceding the name <em>Alice</em> in the book <em>Alice’s Adventures in Wonderland</em> (1865).</p>
<p>Programmer competency tasks are fairly common but, in the constellation of what would-be programmers are asked to do, this one seemed different.</p>
<p>This task is not remarkable in its difficulty. In general, I tend to get sucked into coding when I'm presented with something challenging. I suspect this is the case for almost anyone who codes regularly. Programming can be very difficult, but it's often difficult in exactly the right way: even partial successes are immediately observable and utterly distinct from an outright failure. In video game studies, gamers motivated like I am are called "achievers." Making something work, especially it was hard, feels good, much like beating a boss, or earning a badge, or unlocking a secret level.</p>
<p><h3>A Solution</h3>
But I can’t say that the Alice Problem really appeals to my achiever side, because it isn't very hard. A simplified solution might go something like this:</p>
<ol>
<li>Read the full text of <em>Alice’s Adventures in Wonderland</em> into memory and store it as a string.</li>
<li>Go through the text and tokenize such that every word is treated separately from every other word.</li>
<li>Use one of any number of Part-of-Speech (POS) taggers to generate a best guess for the part of speech for each token.</li>
<li>Go through the text word by word. If the word is "Alice," look at the part of speech value to the left (one common approach to this type of question is called Key Words in Context or KWIC).</li>
<li>If the word to the left is an adjective, store its value. If the word has appeared before, add to a count of the total number of occurrences for that adjective</li>
<li>Sort the results by the number of occurrences.</li>
<li>Return or print the result.</li>
</ol>
<p><h3>Some Code</h3>
Using Python, my typical programming language of choice, this task is especially easy to tackle because the pieces needed to accomplish the tasks are all associated with one very popular library, the Natural Language Toolkit (nltk). This script does approximately what my list above describes.<a class="footnote" href="#note_1">1</a></p>
<pre>
import nltk
with open('alice.txt') as a:
    alice_text = a.read()
alice_tokens = nltk.word_tokenize(alice_text.lower())
alice_pos = nltk.pos_tag(alice_tokens)
alice_pos = [i for i in alice_pos if i[0].isalpha()]
adjs = []
for i, j in enumerate(alice_pos):
    if j[0]=='alice':
        before = i-1
        if alice_pos[before][1] == 'JJ':
            adjs.append(alice_pos[before][0])
from collections import Counter
print(Counter(adjs).most_common())
</pre>
The output, using the Natural Language Toolkit's default Part-of-Speech tagger, is a list of term counts that looks like this:
<pre>
[('thought', 26), ('poor', 11), ('cried', 7), ('little', 3), ('exclaimed', 3), ('shouted', 1), ('red', 1), ('inquired', 1), ('foolish', 1), ('interrupted', 1), ('pleaded', 1), ('replied', 1), ('noticed', 1), ('miss', 1), ('anxious', 1), ('different', 1), ('upon', 1)]
</pre><p><h3>Some Immediate Caveats</h3>
Before anything else, I should acknowledge issues with the accuracy of this tagger. It has incorrectly labelled "thought," "cried," and multiple other verbs as adjectives. We might hypothesize that adjectives such as "poor" and "little" will remain our top results with these mislabeled verbs excluded, but a parser with this
many false positives could be missing any number of adjectives. On the other hand, these verbs are all like to be associated with dialogue attribution (as in "cried Alice" and "thought Alice"), so the errors could be concentrated around this particular sentence structure.</p>
<p>I also want to signal my awareness of numerous general ways to improve the code overall. An employer hiring an imaginary programmer for a digital humanities initiative might be specifically interested in whether the candidates used object-oriented programming,
particular libraries, and any number of stylistic approaches.</p>
<p>These caveats aside, the necessary steps I've outlined would be quite familiar to any programmer computationally-inclined digital humanist, so
I can see why a task like this might serve as a reasonable as a measure of a programmer's ability to write code that engages with a humanities computing problem.</p>
<p><h3>Simplicity is Complicated</h3>
The problem is simple. The problem is deceptively complicated. Welcome to humanities computing.</p>
<p>One solution or another is easy to code, but the underlying question is complex, especially if one chooses to emphasize how this problem relates to reading <em>Alice's Adventures in Wonderland</em>.
There is a question beneath this problem that has little to do with adjectives directly to the left of the name <em>Alice</em>. Rather, adjectives and adjacency are boundaries for the applicant to work with while sketching a computational perimeter
around a more nuanced question:</p>
<blockquote>
"How does Carroll describe Alice, and what are the implications of this description?"
</blockquote>
Or, perhaps more ambitiously:
<blockquote>
"How does Carroll's description of Alice compare with other characters in other texts?"</blockquote>
Or, perhaps going even further:
<blockquote>
"How does descriptive language in <em>Alice's Adventures in Wonderland</em> compare broadly to other narratives with imagined landscapes?
And how might descriptive patterns help a reader situate <em>Alice</em> in relation to its historical and formal context?"
</blockquote><p>These questions should have implications for the various humanities scholarship that has considered <em>Alice</em>'s place in the history of children's literature.
For example, Beatrice Turner's "'Which is to be master?': Language as Power in <em>Alice in Wonderland</em> and <em>Through the Looking-Glass</em>"
argues that "most of [Alice's] exchanges with the inhabitants of Wonderland and the Looking-glass world" are marked
by a "power imbalance ... that is worked out at the level of language" (246).<a class="footnote" href="#note_2">2</a> I am not immediately persuaded by Turner's argument,
but it represents for me a productive site of engagement with the text because it invites additional interpretation.</p>
<p>Most immediately, Turner's work reminds me that questions about descriptive norms in <em>Alice's Adventures in Wonderland</em> and other children's fiction are affected by
the way people (men, women, children, adults) interact, and those interactions legitimize or undermine a person's right to observe, react, and speak.</p>
<p>I think Turner's sharpest point is that Alice is a little girl, and the characters around her, despite being erratic and nonsensical and even infuriating at times, are basically cast as adults.</p>
<p>"The texts grant linguistic control to those who inhabit Wonderland and the Looking-glass world," she argues, "and, in doing so, define them as adults. They use this
control in a very adult way, too: they exercise the adult’s right to tell the child what she is" (249). Looking at adjectives to the immediate left of the name <em>Alice</em> is merely one
immediate and quantifiable way to gesture at broader issues like this one. The fact that <em>Alice</em> is described as little, poor, foolish, anxious, and different begins to substantiate
Turner's initial observation about how Carroll frames Alice.</p>
<p><h3>"Through the Looking Glass" as a Strained Metaphor for Something Far Less Interesting than Interdimensional Travel</h3>
One issue with "adjectives to the left of Alice" is that it's a relatively narrow way to think about how Alice is described. To begin to address the broader question,</p>
<p><blockquote>
"How does Carroll describe Alice, and what are the implications of this description?"
</blockquote>
I would prefer a computational method with more interpretive reach. Instead of designing a tool to look specifically for adjectives next to Alice,
for example, we could design an instrument to ask what kinds of term pairs tend to co-occur more generally in the novel. To set up this test, I could use the NLTK's collocations function.</p>
<pre>
from nltk.collocations import *
bigram_measures = nltk.collocations.BigramAssocMeasures()
at = [i for i in alice_tokens if i.isalpha()]
finder = BigramCollocationFinder.from_words(at)
finder.apply_freq_filter(3)
ignored_words = nltk.corpus.stopwords.words('english')
finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)
terms = []
for i in finder.nbest(bigram_measures.pmi, 10000):
    if "alice" in i:
        print(i)
</pre><p>This code uses a function called "collocations" to look for common bigrams in <em>Alice's Adventures in Wonderland</em>. By bigrams, I mean pairs of adjacent words.
For the purposes of this measure, I've removed all punctuation from the text and made all words lowercase so that "afraid" and "Afraid", for example, would read as the same term.
I've set the code to ignore any term that doesn't appear at least three times, and I've removed from consideration any pairs that use excessively common "function words" like <em>the</em>, <em>as</em>, and <em>in</em>.
(For a full list of these stopwords, see this <a href="https://gist.github.com/sebleier/554280">Github Gist</a>.)
The above code snippet will only output term pairs of one of the terms is "Alice." The result of collocated terms does not focus on any particular part-of-speech, but several adjectives are easy to pick out.</p>
<pre>
('alice', 'ventured')
('alice', 'indignantly')
('exclaimed', 'alice')
('poor', 'alice')
('thought', 'alice')
('cried', 'alice')
('together', 'alice')
('alice', 'replied')
('alice', 'waited')
('said', 'alice')
('alice', 'hastily')
('alice', 'felt')
('alice', 'looked')
('alice', 'asked')
('alice', 'thought')
('alice', 'could')
('alice', 'began')
('alice', 'rather')
('caterpillar', 'alice')
('alice', 'heard')
('alice', 'quite')
('alice', 'must')
('alice', 'went')
('alice', 'said')
('little', 'alice')
</pre><p>In the context of this collocations analysis, the only two adjectives that rank among the top associations with "Alice" are "poor" and "little."
One renders the protagonist (albeit ironically) as an object of pity, and the other reinforces her status as a child and a figure of reduced physical and social stature.</p><p>Perhaps more striking is the fact that so many of these collocations situate Alice in dialogue. Terms like "asked", "began", "said", "exclaimed", and "ventured" are specific dialogue tags (i.e., verbs).
Terms like "thought", "look", "felt", "heard", and "indignantly" indirectly situate her in dialogue as well. These terms convey an Alice who is often listening, reacting internally, or conveying confusion or frustration without
necessarily taking specific actions to resist.</p><p><h3>A Continuously Widening Spiral of Comparison</h3></p>
<p>Still, we might ask whether these word associations are the symptoms of a character constrained by her age and gender, or simply the kinds of words that any main character is
likely to be associated with in a children's novel of this time period. After all, the rise of dialogue in 19th-century fiction could easily account for at least some of these associations.</p><p>One way to address these concerns is to compare <em>Alice's Adventures in Wonderland</em> to other texts (or authors, or genres, etc.).
Take, for example, a a quick analysis of just a few female protagonists from novels about girls who visit other worlds. How do descriptions of these female main characters differ from how Alice is described?</p><p>A question like this is one that Turner (and many others), using situationally specific methods, cannot answer. Queries with large-scale scope are notoriously difficult to approach without computation.</p><p>An extensive search for novels about girls who visit other worlds would no doubt reveal any examples, but a few very well known archetypes come to mind: Dorothy in
<em>The Wonderful Wizard of Oz</em> (1900), Wendy in <em>Peter and Wendy</em> (1910), and Lucy and Susan in <em>The Lion, the Witch, and the Wardrobe</em> (1950).</p><p>If we replicate the two computations I performed on <em>Alice's Adventures in Wonderland</em> using these three texts, we can begin to form a basis for comparison.</p><p>It's important to note that these are all male authors. Here I am not asking a question like, "Did women authors of the 19th and 20th centuries write female characters with more signs of individual agency than men," although I think a question like this one would be fascinating to explore. Instead, I'm merely
investigating which terms are most often adjacent to five characters names in four very well known novels about girls who visit fantasy realms.</p><pre>
import nltk
import nltk.collocations
def collocation_analysis(text, character):
    with open(text) as a:
        my_text = a.read()
    my_tokens = nltk.word_tokenize(my_text.lower())
    bigram_measures = nltk.collocations.BigramAssocMeasures()
    at = [i for i in my_tokens if i.isalpha()]
    finder = BigramCollocationFinder.from_words(at)
    finder.apply_freq_filter(3)
    ignored_words = nltk.corpus.stopwords.words('english')
    finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)
    terms = []
    pairs = []
    for i in finder.nbest(bigram_measures.pmi, 10000):
        if character in i:
            pairs.append(i)
    return pairs

output = []
for i, j in comparison_texts:
    pairs = collocation_analysis(i, j)
    output.append(pairs)
</pre><p>Granted, these texts are separate by many years, and Lucy and Susan might be prone to appearing as outliers because they are two of four main characters in <em>The Lion, the Witch, and the Wardrobe</em>.
Still, I think the commonalities among these books are more important than the differences.</p>
<p>The above code will output a list of term pairs for each text just like the one for Alice shown above. However, this output doesn't necessarily help us compare the various characters.
In the following table, I've made a row for each term and a column for each character. An X in a cell means that a given term and a given character can be considered a computed association:</p><table class="table table-bordered table-hover table-condensed">
<thead><tr><th title="Field #1" ></th>
<th title="Field #2">term</th>
<th title="Field #3">lucy</th>
<th title="Field #4">susan</th>
<th title="Field #5">dorothy</th>
<th title="Field #6">wendy</th>
<th title="Field #7">alice</th>
</tr></thead>
<tbody><tr>
<td align="right">0</td>
<td>saw</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">1</td>
<td>picked</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">2</td>
<td>story</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">3</td>
<td>queen</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">4</td>
<td>exclaimed</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">5</td>
<td>went</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">6</td>
<td>little</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">7</td>
<td>returned</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">8</td>
<td>asked</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">9</td>
<td>could</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">10</td>
<td>presently</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">11</td>
<td>together</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">12</td>
<td>heard</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">13</td>
<td>thought</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">14</td>
<td>answered</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">15</td>
<td>began</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">16</td>
<td>lady</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">17</td>
<td>walked</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">18</td>
<td>waited</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">19</td>
<td>wendy</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">20</td>
<td>whispered</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">21</td>
<td>put</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">22</td>
<td>hastily</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">23</td>
<td>mother</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">24</td>
<td>said</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">25</td>
<td>poor</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">26</td>
<td>peter</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">27</td>
<td>last</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">28</td>
<td>ventured</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">29</td>
<td>sat</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">30</td>
<td>felt</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">31</td>
<td>replied</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">32</td>
<td>must</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">33</td>
<td>indignantly</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">34</td>
<td>caterpillar</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">35</td>
<td>suddenly</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">36</td>
<td>came</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">37</td>
<td>looked</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">38</td>
<td>would</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">39</td>
<td>rather</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">40</td>
<td>quite</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">41</td>
<td>stood</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">42</td>
<td>see</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">43</td>
<td>cried</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
<td>XXXXX</td>
<td>XXXXX</td>
</tr>
<tr>
<td align="right">44</td>
<td>well</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
</tr>
<tr>
<td align="right">45</td>
<td>moment</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">46</td>
<td>says</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">47</td>
<td>knew</td>
<td>-----</td>
<td>-----</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
</tr>
<tr>
<td align="right">48</td>
<td>found</td>
<td>XXXXX</td>
<td>-----</td>
<td>XXXXX</td>
<td>-----</td>
<td>-----</td>
</tr>
</tbody></table><p>Based on this table, we can notice some immediately fascinating aspects of the comparison. It makes it much easier to find terms associated with only one or two characters, as well as associations present for all <em>but</em> one or two characters. For example:</p><p>Lucy: uniquely associated with last and suddenly. No unique absences.</p>
<p>Susan: uniquely associated with presently, whispered, and Peter. Uniquely not associated with cried and could.</p>
<p>Wendy: uniquely associated with story, lady, mother, see, says, and knew. Uniquely not associated with absent and asked
<p>Dorothy: uniquely associated with returned, answered, walked, and put. No unique absences.</p>
<p>Susan and Wendy: neither associated with thought or looked</p>
<p>Alice and Dorothy; associated with replied, exclaimed, went</p>
<p>Dorothy and Wendy: associated with saw, would</p>
<p>Lucy and Wendy: associated with moment</p>
<p>Alice: uniquely associated with little, poor, together, heard, began, waited, hastily, ventured, must, indignantly, caterpillar, rather, quite</p><p>These findings warrant more discussion than I'm planning on doing here today. For now, a few highlights. First, this comparative approach only strengthens the association between Alice, little, and poor established by a part-of-speech tagging approach.
Further, the pairing of waited and hastily, typically oppositional terms, reminds of a character constantly trying to move along but getting held up by others. Similarly, the term <em>began</em>, likewise, conjures images of a character attempting to speak but getting consistently interrupted.
Adding to the sense of both situational and verbal irony are the terms <em>rather</em> and <em>quite</em> both of which seem likely to be tongue-in-cheek qualifiers. </p><p>In this example, we knew the main characters' names, so the comparison is a bit easier. Scaling this question beyond our example would requiring making a dictionary of main character names or developing a method that detected character names automatically.
This is just one example of a continuously widening spiral of comparison. Additional layers are always possible, which is one of the main reasons it's so appealing to sit and tinker.</p><p>In the past, I have described digital humanities using the metaphor of an investigator who uses advances tools and approaches look through a keyhole, only to find that, inside the locked room there is only a mirror.
This is to say that digital humanities methods, too often, become lenses through which the only result is a more nuanced understanding of digital humanities. I am confident that meditating on
the advantages and limits of our methods has purchase, yet, here I believe light is also shed on <em>Alice's Adventures in Wonderland</em>.</p><p><p>I must concede, of course, that it is possible that these alternative close reading strategies mostly confirm what others have noticed using more traditional literary analysis methods.
If this is so, then code is still a way to get to where we want to go, a way to establish the habits of mind that lovers of close reading are always trying to instill in their students and colleagues.
The real challenge is taking the time to share one's results with others. This is inevitably a decision to stop, which eventually requires stopping. And so I have chosen to conclude with a partial list of how much more I want to do.</p>
<p><h3>Ideas for Follow-up</h3></p>
<div class="follow-up-entry">Compare adjectives overall to lots of novels</div>
<div class="follow-up-entry">On many novels: return the names after "little" (and other adjectives) ranked by how often those names are referred to as little. Are those names gendered?</div>
<div class="follow-up-entry">Explore character-based sentiment tagging, in response to (if possible) Michael Mendelson's "The phenomenology of deep surprise in <em>Alice's Adventures in Wonderland</em>"</div>
<div class="follow-up-entry">Use SpaCy or Parsey McParseface or for better POS tagging</div>
<div class="follow-up-entry">Explore how to perform similar analysis on novels without knowing main characters' names</div>
<div class="follow-up-entry">Attempt to run using pronoun disambiguation</div>
<div class="follow-up-entry">Re-run multi-novel analysis using collocations two and three words away from characters' names</div><p><h3>Notes</h3></p>
<div class="note_entry" name="note_1">1. Code excerpts can be viewed in or downloaded/run from the .ipynb file in <a href="https://github.com/mjlavin80/the-data-humanist-jupyter-notebooks/tree/master/alice">this folder</a> in my Jupyter Notebooks Github repository</div>
<div class="note_entry" name="note_2">2. Turner, Beatrice. "'Which is to be master?': Language as Power in <em>Alice in Wonderland</em> and <em>Through the Looking-Glass</em>,"
 <em>Children's Literature Association Quarterly</em>, 35.3 (Fall 2010): 243-254.
</div>
</div>
  </div>


</div>
  </div>
  <footer>
      <div class="container"><div class="row">
    <p>&copy; Copyright 2016 by Matthew J. Lavin</p>

</div>
</div>
  </footer>
  <!-- JavaScript -->
  <script src="/static/js/jquery-3.1.0.min.js"></script>
  <script src="/static/dist/js/bootstrap.js"></script>
</body>
</html>
