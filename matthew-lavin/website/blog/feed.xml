<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title type="text">Feed One</title>
  <id>urn:uuid:2ae5ada5-f205-310d-9478-55041461783a</id>
  <updated>2017-12-27T00:00:00Z</updated>
  <link href="http://matthew-lavin.com/blog/" />
  <link href="http://matthew-lavin.com/blog/feed.xml" rel="self" />
  <author>
    <name></name>
  </author>
  <generator uri="https://github.com/ajdavis/lektor-atom" version="0.2">Lektor Atom Plugin</generator>
  <entry xml:base="http://matthew-lavin.com/blog/terms-and-conditions/">
    <title type="text">Terms and Conditions for a Culture of Open Data</title>
    <id>urn:uuid:63ca0ecb-dfca-35be-b5d6-af085d365f85</id>
    <updated>2017-12-27T00:00:00Z</updated>
    <link href="http://matthew-lavin.com/blog/terms-and-conditions/" />
    <author>
      <name>Matt Lavin</name>
    </author>
    <content type="html">&lt;p&gt;This post is response to Andrew Piper's recent &lt;a href=&quot;https://txtlab.org/2017/12/an-open-letter-to-the-mla/&quot;&gt;&quot;An Open Letter to the MLA&quot;&lt;/a&gt; (12/21/2017), as well as a response to some of the reaction it generated on Twitter. I want to express solidarity with Andrew and to acknowledge that many members of our community have raised important issues that complicate his initial statement. Nevertheless, with the MLA's annual convention soon to come, I believe that now is an especially timely moment to come together and advance our public conversations about data-driven research in the humanities.&lt;/p&gt;
&lt;p&gt;Before all of that, I'd like to say a little about myself to contextualize my response. I'm not an especially well known digital humanities personality, but I've been engaged with DH as a scholar and a teacher since 2012, which was the year I defended my dissertation. I worked as a postdoctoral scholar at the Center for the Digital Research in the Humanities at the University of Nebraska - Lincoln, and I spent two years after that as Associate Program Coordinator for an institution-wide Mellon grant focusing on digital humanities and integrative learning at St. Lawrence University in Canton, NY. For the past two-and-a-half years, I've been Director of the Digital Media in the English Department at the University of Pittsburgh.&lt;/p&gt;
&lt;p&gt;I should also say that, especially in terms of my scholarship, I have spent the last few years focusing on methodological training rather than public visibility. I've been learning to code and working in 'alt-ac' jobs that usually involve some kind of hands-on digital making. My pre-DH scholarship focused on spaces where authorship studies overlaps with literary studies and, like Katherine Bode, Andrew Piper, and Ted Underwood (to name a few better known examples) I believe that computational methods (including but not limited to large scale data mining and machine learning approaches) have a tremendous potential to assist scholars in revisiting core book history and sociology of literature research questions. About a year ago, I started a small website called humanitiesdata.com in an attempt to make finding and sharing datasets of interest to the humanities a bit easier. This background informs my perspective on the idea of open data. I recognize that others have stories of their own that inform their points of view.&lt;/p&gt;
&lt;p&gt;Below, I have attempted to sketch out what open data means to me. I see open data as set of philosophies that often includes stances on access, timeliness, and reproducibility.&lt;/p&gt;
&lt;p&gt;Access relates to the idea that some data ought to be open to the public, in formats that facilitate various uses. I would argue that the MLA International Bibliography is a good candidate for this status but, historically, I believe access to the bibliography has been restricted to members. Further, now that the bibliography is no longer in print but accessed instead as a searchable database, access is provided through subscriptions by three very prominent vendors: Cengage, EBSCO, and ProQuest. These companies collect subscription fees, mostly from academic libraries in exchange for access. Presumably the MLA is paid a percentage. If the MLA International Bibliography were to become truly open, the profit potential of these data would probably be affected.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Yes. The conflict between data-providers and researchers often takes this form: &lt;a href=&quot;https://t.co/7o0WRzDoF5&quot;&gt;pic.twitter.com/7o0WRzDoF5&lt;/a&gt;&lt;/p&gt;&amp;mdash; Ted Underwood (@Ted_Underwood) &lt;a href=&quot;https://twitter.com/Ted_Underwood/status/944310743561834499?ref_src=twsrc%5Etfw&quot;&gt;December 22, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;Timeliness relates to the idea that data can't really be open if it comes only after long delays. This principle is especially relevant to issues of government transparency, but it also applies to datasets that accompany scholarly publications. A work of scholarship associated with a dataset likely contains the most rigorously constructed interpretation of results for that dataset that will ever exist, so publishing data and code alongside an article that depends upon both can be seen as the best way to be sure that an article's most engaged respondents will have the best possible tools in hand to scrutinize the work.&lt;/p&gt;
&lt;p&gt;This brings me to reproducibility. The best way to scrutinize computational work and build on it is to recreate the source code and data and rerun a scholar's experiments. Reproducibility is not the most common way of thinking about scholarship in literary studies, at our level, because it often taken as a prerequisite that a scholar's quotations from source texts should be accurate and correctly cited. Yet editors at many scholarly journals spend countless hours double-checking citations, and any reader of a periodical can conceivably do the same. As far as I know, only in a data-driven context does the humanities accept work where the objects being analyzed might not be available for this kind of post-publication examination. Preventing reproducibility hurts scholarship by opening the door for fraudulence and putting up barriers for follow up work.&lt;/p&gt;
&lt;p&gt;Some may argue that this examination and follow up work isn't happening anyway. To this I would say that openness invites open discussion and collaboration. It doesn't guarantee that these things will happen, but closed data practices do all but guarantee that these practices will be difficult or impossible.&lt;/p&gt;
&lt;p&gt;In short, I believe digital humanities should consider access to timely, multi-format, and reproducible data as a core set of values. A culture of open data would strengthen our scholarly ecosystem, as well as the work it produces. How we deliver this is a subject for debate and discussion, but this is the first point on which I would like to express solidarity with Andrew Piper. Andrew has called upon scholarly organizations like the MLA to reevaluate the practice of partnering with for-profit companies to provide access to its data and to &quot;stop signing license agreements that limit access and the public circulation of their data.&quot; He has argued that libraries should stop signing license agreements that limit such access. I believe that this is a question that the MLA should discuss and debate as a group and in the open. Should this question not, at least, be put to its members?&lt;/p&gt;
&lt;p&gt;The MLA constitution states, &quot;The executive director shall see that all actions of the Executive Council and the Delegate Assembly are reported in an appropriate publication of the association within a reasonable period of time. On petition of one percent of the association, any such action shall be subjected to a referendum mail ballot of the entire membership.&quot; I am by no means an expert on MLA procedures, but a carefully crafted petition for a full membership vote at the 2019 convention seems like an appropriate way to raise Andrew's question for public debate.&lt;/p&gt;
&lt;p&gt;I have seen numerous Tweets raising the point that the MLA and its vendors are already engaged in efforts to develop an API (application programming interface), which will provide exactly the kind of access Andrew Piper and others are asking for.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I have been biting my tongue, but can’t continue to do so. What those of you passing around that open letter about the MLA’s data sharing practices haven’t been told is that the org has informed the author repeatedly that it’s developing a new platform with an open API +&lt;/p&gt;&amp;mdash; Kathleen Fitzpatrick (@kfitz) &lt;a href=&quot;https://twitter.com/kfitz/status/944221843375951872?ref_src=twsrc%5Etfw&quot;&gt;December 22, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;that is designed support exactly the kind of research the author wants to do. That sort of development takes time, and the org has asked for (and obviously not received) his patience.&lt;/p&gt;&amp;mdash; Kathleen Fitzpatrick (@kfitz) &lt;a href=&quot;https://twitter.com/kfitz/status/944222123828146176?ref_src=twsrc%5Etfw&quot;&gt;December 22, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;This point should be acknowledged as both a valid critique and, I believe, insufficient as a response to Andrew's concerns.&lt;/p&gt;
&lt;p&gt;This point inevitably crosses into questions some have raised about whether Andrew was sufficiently patient with established processes for accessing and sharing MLA data. Andrew, by scraping the current interface and sharing data, may have violated a vendor's terms and conditions. However, after reading those terms and conditions, they do seem broad and difficult to adhere to. Further, I have to express sympathy for someone like Andrew, as the emotional reality of working with large datasets is often a mix of confusion and frustration. Although it does seem that Andrew made some mistakes, I think mistakes like these are understandable. As more citizens of our scholarly community learn to code, these types of run-ins are going to become increasingly common. Meanwhile, as Kathleen Fitzpatrick, Paige Morgan, and others expressed on Twitter, we have to find ways to acknowledge and respect the hard work that other practitioners are doing behind the scenes to provide access to these kinds of services.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I&amp;#39;m sorry you&amp;#39;re having to deal with this. (It&amp;#39;s the latest in a series of examples I&amp;#39;ve seen wherein people in research-focused roles fail to understand institutional processes/how institutional infrastructure works.&lt;/p&gt;&amp;mdash; Paige Morgan (@paigecmorgan) &lt;a href=&quot;https://twitter.com/paigecmorgan/status/944270056237813760?ref_src=twsrc%5Etfw&quot;&gt;December 22, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;I also want to address the idea providing &quot;non-consumptive access,&quot; which Amanda French raised in a Tweet.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I do know for a FACT that the MLA is committed to providing “non consumptive” access to researchers who want to analyze its data in the aggregate, but, um, they are building that and it doesn’t exist yet.&lt;/p&gt;&amp;mdash; Amanda French (@amandafrench) &lt;a href=&quot;https://twitter.com/amandafrench/status/944309938691674112?ref_src=twsrc%5Etfw&quot;&gt;December 22, 2017&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;With literary texts, non-consumptive alternatives to raw text files make sense as a way to provide data without providing a version of that data that can be modified back into an e-book format that one might substitute for buying the book legally. In the context of the MLA International Bibliography, it's hard to imagine what a non-consumptive format would look like. I'm obviously open to being corrected on this, but any csv of the database could be re-engineered into a ProQuest-type interface. To me, the best solution is to make the data available through an API and as downloadable files, on the condition that the user will not use the dataset to create a front-end interface. Many datasets are shared with similar terms and conditions,  and violators are subjected to the same kind of takedown notices that Andrew received.&lt;/p&gt;
&lt;p&gt;In specific response MLA practices, I think some crucial questions should be addressed in as public a form as possible.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Since we have heard repeatedly that an API is being developed, what is a reasonable timeline for users to expect access? How can we get periodic updates about the status of the API? How can code-savvy scholars help develop it?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What should MLA data policies toward its data be in the meantime?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why is hosting a self-made dataset online incompatible with the MLA's intended data policies? What are the current policies with regard to accessing the data for computational purposes?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Answers to some or all of these questions may be online somewhere. I looked on the MLA's website and didn't find them. I would have hoped to see them articulated or linked in the FAQ section of the MLA International Bibliography.&lt;/p&gt;
&lt;p&gt;Finally, I would raise the question of how we can best engage with these questions non-adversarially, or at least less adverserially. Past mistakes aside, I believe that most of us want the same thing: a shared asset that benefits MLA members and facilitates a better understanding of our field(s) of study. I can't speak to what has gone on behind the scenes, and I wish to express only respect for anyone who feels that my call for more openness is an attack of any kind. So many people have put so much effort into making the MLA International Bibliography what it is today, and Andrew's eagerness to use the database for his scholarship can be regarded as a testament to that fact.&lt;/p&gt;
&lt;p&gt;&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://matthew-lavin.com/blog/book-reviews-as-data/">
    <title type="text">Book Reviews as Data</title>
    <id>urn:uuid:0d758219-d966-31e7-8b02-e72edd720594</id>
    <updated>2017-10-03T00:00:00Z</updated>
    <link href="http://matthew-lavin.com/blog/book-reviews-as-data/" />
    <author>
      <name>Matt Lavin</name>
    </author>
    <content type="html">&lt;p&gt;In May of 1905, a review of &lt;em&gt;The Troll Garden&lt;/em&gt;, Willa Cather’s first published collection of
short stories, appeared in The New York Times. The title of the review is &quot;Promising Stories&quot; and the
length is three paragraphs, or what seems to be a rather short notice when we compare it to reviews of
&lt;em&gt;The Troll Garden&lt;/em&gt; from &lt;em&gt;Harper’s Weekly&lt;/em&gt;, &lt;em&gt;Bookman&lt;/em&gt;, or &lt;em&gt;Atlantic Monthly&lt;/em&gt;,
 all of which are included in &lt;em&gt;Willa Cather: The Contemporary Reviews.&lt;/em&gt;&lt;a class=&quot;footnote&quot; href=&quot;#note_1&quot;&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/troll-garden.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;But what if we compare this review of &lt;em&gt;The Troll Garden&lt;/em&gt; to other reviews in &lt;em&gt;The New York
Times&lt;/em&gt;, or other reviews in &lt;em&gt;The New York Times&lt;/em&gt; in 1905, or other reviews in &lt;em&gt;The New
York Times&lt;/em&gt; in May of 1905 to characterize its length? &lt;em&gt;The New York Times&lt;/em&gt; archive API
makes these comparisons relatively easy, as one can quite easily construct a Python script to
retrieve review metadata, including review word counts, by month and year. And here is what we find:&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/nytimes1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;These word lengths do not have a normal distribution, i.e., the iconic bell curve we might remember
from a statistics class. Instead, they range from 29 to 4,492 words long. A review cannot be shorter
than 0 words, the median review length is 287 words, and the largest review length is much larger
than most of the reviews. We therefore see what is called a distribution converging to log-normal.
Using a log function, we can convert the values to a normal distribution, and then analyze each
observation's relationship to the norms of the data.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/nytimes2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;A quick way to compare a value to a group of values is to calculate its z-score. You may remember
from statistics class that an observation's raw difference from the mean can be deceptive.
Being an inch taller than the average could be a little, or it could be a lot, depending on how
many observations have been made, and how varied the recorded heights are. A z-score measures an
observation’s difference from the mean scaled to the standard deviation. For example, the review
of Cather’s collection has a z-score of -.3059, which is to say that it is less than one third of
one standard deviation away from the norm. A statistically accurate description would characterize
the review as being within the typical length range for &lt;em&gt;The New York Times&lt;/em&gt; in April 1905.&lt;/p&gt;
&lt;p&gt;Perhaps someone in the audience here today is already wondering what the point this introduction
has been. It’s not an unfair question. With this anecdote, I wanted to raise two related topics
that I will come back to as I speak. The first is what tends to happen when we use heuristics
to evaluate ostensibly straightforward things like size, frequency, density, or duration instead
of taking measurements. Second, measuring any number of things is easier when we (1) have data
that represents something measurable and (2) use a computer to count something what would otherwise
take a very long time to count. These two ideas are always somewhere in the background or foreground
when we talk about digital humanities because so much of our work brings humanities interpretation
into contact computational tools. As Andrew Piper argues in the inaugural issue of &lt;em&gt;Cultural
Analytics&lt;/em&gt;, digital humanities must not merely be &quot;computer science applied to culture&quot; but
instead &quot;a wholesale rethinking of both of these categories.&quot; In other words, DH can call our
attention to limits of hermeneutics and the limits of quantification, and it can have a generative
effect on both kinds of inquiry.&lt;/p&gt;
&lt;p&gt;In this paper, I focus on book reviews of the turn-of-the century United States as crucial, currently
undervalued book historical objects. I frame my analysis with several important stages of the data
lifecycle—study design, planning, and analysis; data creation and collection; data processing; data
preservation, distribution, and discovery, and data re-use. This model, I will argue, has enormous
potential to guide the creation of large-scale, publicly available book review datasets, and to
underscore longstanding compatibilities between book history, and large scale humanities computing.
My presentation is deeply tied to a set of principles for conscientious work in this vein that I have
been developing for myself, and it is also indicative of a direction I would like to see the book
history discipline continue to take.&lt;/p&gt;
&lt;h3&gt;The Data Lifecycle&lt;/h3&gt;
&lt;p&gt;What is the data lifecycle? This interpretive concept or model has become something of a librarian's
slideshow cliché.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/lifecycle-all.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Lifecycle diagrams are liable to show up as flow charts; brightly colored circles
with arrows; A mostly blue geometric diamond shape with one green triangle that says &quot;Dependent
Processes&quot;; swirly thingies making up an outer circle that seems to be swirling around an inner circle
that’s swirling in the opposite direction; an infographic with the universal icons for a server,
a computer, downloading from the cloud and ... I think that's a Word War II fighter plane. And many
more. Just past this preponderance of icons, however, is potentially crucial perspective on how
research data move through an ecosystem of interlinked practitioners. For this reason, I want to
emphasize the model as described by the Data Documentation Initiative (DDI).&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/ddi-lifecycle.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The DDI Lifecycle version 3.0 emphasizes the study concept, data collection, data processing, data
archiving and distribution, data discovery, and data analysis. As with most models, repurposing is
considered the end of one iteration of the lifecycle and the beginning of new one.&lt;/p&gt;
&lt;h3&gt;Phases I and VII: Study Concept and Data Analysis&lt;/h3&gt;
&lt;p&gt;I have paired the study concept stage (sometimes called the planning stage) of the lifecycle with
the data analysis stage because so much of data creation, conversion, and modeling pertains to the
kind of queries one would like to execute. Generally, datasets are generated by a specific study,
or as a purchasable commodity that anticipates a known demand associated with an area of study or
a set of questions. Most among us, I suspect, would prefer to think first about our research
questions and then about the data strategies and methods that would fit those questions. In a
&quot;humanities computing&quot; context, however, we must pair this kind of discussion with a general
understanding of the kind of data we would need to use certain methods or answer certain questions.&lt;/p&gt;
&lt;p&gt;For many, reviews are everyday documents so familiar as to seem self-evident, pure expressions of
recommendation, condemnation, or something between the two. The review is too seldom treated as a
highly rehearsed and performative genre with deep rhetorical and material codes of information
transfer. Book historians and book historically sensitive literature scholars, meanwhile, have
worked extensively with book reviews and have done much to dispel the idea that the content of
periodicals can be taken as neutral information. Gerard Genette theorizes &quot;the review&quot; as a
paratextual or intertextual document; Pierre Bourdieu dwells extensively on the prestige function
of the critic. Nina Baym’s &lt;em&gt;Novels, Readers, and Reviewers: Responses to Fiction in
Antebellum America&lt;/em&gt; (1984) consults &quot;more than two thousand novel reviews&quot; that make &quot;some
attempt at description and evaluation&quot; (14). Joan Shelley Rubin's &lt;em&gt;The Making of Middlebrow
Culture&lt;/em&gt; (2000) engages forcefully with how reviewers participating in construction the idea
of middlebrow culture. Numerous book historians have looked to book reviews for signs of how an
author, text, or genre was received. More recently, Ashley Champagne has turned to Goodreads reviews
for evidence of how readers participate in literary canon making, and Allison Hegel has done
computational analysis on a range of contemporary review types in search of patterns that
characterize how genre informs reader expectations and judgments of quality.&lt;/p&gt;
&lt;p&gt;For the moment, I'm lumping so-called professional reviews with their nonprofessional counterparts,
but many of the people I have just named parse these categories--and the liminal states between
them--in important ways.&lt;/p&gt;
&lt;p&gt;To get to a point where pursuing these questions computationally is possible, we must understand
that web accessible and computable are not the same thing. The preponderance of digital page images
and OCR have given us the false impression that everything is available and at our fingertips,
but this is far from true. Even an excellent resource like the reader experience database can be
browsed and searched much more easily than it could be computed over. Champagne and Hegel have
turned to Goodreads precisely because its content can be webscraped. If we have each review as its
own block of machine readable text and some basic metadata about each review, we can already employ
some of the most well established distant reading techniques associated with digital humanities,
such as sentiment analysis, topic modeling, term collocations, part of speech tagging, and named
entity recognition (e.g., computationally recognizing references to people and places). For many of
these methods, we only a spreadsheet of all terms and term counts in a document. However, most
reviews are not yet in this state.&lt;/p&gt;
&lt;p&gt;Certain queries on literature, such as an analysis of various characters' patterns of speech in a
novel, require extensive hand encoding. Analogously, for reviews, there are many queries that require
the book that is being reviewed to be tagged. There are natural language processing or computer
vision methods to try and determine which book a book review is reviewing, but a book historical
standard would at minimum demand hand correction to avoid lumping different texts with matching
titles, or to group different titles with a common underlying text. Many bibliographers or book
historians would also stress the importance of being able to facet by edition, issue, state, or
impression, for a review is often specific to a one such manifestation.
&lt;img class=&quot;slide&quot; src=&quot;/static/images/amazon.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Take, for example, an Amazon.com product review warning that an on-demand edition of &lt;em&gt;The King
in Yellow&lt;/em&gt; has &quot;the font and layout of a term paper,&quot; or a Goodreads review ...&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/goodreads.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;... that comments extensively on the consequences of choosing the first edition Doubleday text over
the revised and expanded Pennsylvania edition text when preparing the Blackstone Audiobook
version of &lt;em&gt;Sister Carrie&lt;/em&gt;. Such faceting might not yield major results on a large-scale level,
as we may discover that most reviewers believe themselves to reviewing and responding to some
abstracted or Platonic version of whatever text they are reading, but we might at least earn
something about when this widely held myth of a disembodied text is most likely to break down
in the face of materialization.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/bookman.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Going even further, many print reviews discuss numerous books in one monthly or weekly column,
so we want, at minimum, to isolate multi-book reviews into their own category or better still,
tag every block of text to indicate the book being discussed. This is not a straightforward matter
at all when we consider sentences that compare two books or speak generally about all books or
generalize about the author's tendencies.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/women-short-story.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;I would be quite excited to explore further how these kinds of review subgenres affect the
rhetoric of reviews, the forcefulness of review judgments, or the thoroughness of reviewers'
examples to support their claims. Overall, thinking about how reviews are likely to be studied
should help us determine what kind of structure book review data must have to be desirable for
reuse or later expansion.&lt;/p&gt;
&lt;h3&gt;Phase II: Data Collection&lt;/h3&gt;
&lt;p&gt;To consider acquisition or data creation (or conversion of primary resources to data fields)
sufficiently, we must understand the range of norms for book reviews in the context of an already
articulated research question (or a survey of common research questions if the data are to be
produced purely for public access). For two years, I have worked a team of digital humanities
colleagues at the University of Pittsburgh on a project titled &quot;Computational Approaches to Textual
Networks.&quot;&lt;a class=&quot;footnote&quot; href=&quot;#note_2&quot;&gt;2&lt;/a&gt; Our primary goal has been to create workflow models
to address challenges of producing machine-readable textual corpora with strong relational attributes.
&lt;a class=&quot;footnote&quot; href=&quot;#note_3&quot;&gt;3&lt;/a&gt; Our efforts have included surveying the availability of
digitized book reviews, experimenting with workflows to adapt or &quot;up-coding&quot; existing digital assets,
and conducting discrete, small-scale digitization of materials.&lt;a class=&quot;footnote&quot; href=&quot;#note_4&quot;&gt;4&lt;/a&gt;
Our survey of the current landscape of available data suggests a tremendous potential to move from
state where book reviews are highly discoverable and searchable, to a state where book reviews
are fully computable. To summarize:&lt;/p&gt;
&lt;ul class=&quot;blog&quot;&gt;
&lt;li&gt;Sites like HathiTrust and Internet Archive have many searchable volumes of periodicals, but these are not structured to partition individual articles into separate units.&lt;/li&gt;
&lt;li&gt;Chronicling America has lots of dirty OCR page scans containing book reviews, but they are mixed in with all other page content&lt;/li&gt;

&lt;img class=&quot;slide&quot; src=&quot;/static/images/troll-sf.png&quot; /&gt;
&lt;img class=&quot;slide&quot; src=&quot;/static/images/troll-sf-ocr.png&quot; /&gt;

&lt;li&gt;&lt;em&gt;The New York Times&lt;/em&gt; has an API where you can retrieve metadata (review content is labeled
as such) and pdf files, but not underlying full text. Other newspapers have similar searchability
without computability.&lt;/li&gt;
&lt;li&gt;Proquest and others also have a 'review' datatype. You can search and download metadata in small
chunks but will get banned for taking too much too fast.&lt;/li&gt;
&lt;li&gt;I have seen historical reviews modeled or entity referenced to the book or books they review,
but this is a logical next step, so others might be doing it. (Goodreads and Amazon have their own
ways of doing this.)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This brief overview of the field provides a partial sense of what you are likely to find if you go
looking for book reviews to compute with. You find a field with browsing access to much more than
you could ever read, and computational access to very little. If you begin the long process of
making your corpus of book reviews, you will probably find the labor dull and progress slow.
My team has brought in graduate and undergraduate student assistants with mixed results.
As with all things digital, copyright is sometimes a genuine concern and sometimes a convenient
excuse for inaction. If an individual scholar generates data in conjunction with an article,
that scholar has every short-term incentive to guard their data as they might guard a good idea.
Yet I can't help but feel that, as a result of this mix of obstacles and ambiguities and perfectly
reasonable concerns, we are all missing out on something worth doing.&lt;/p&gt;
&lt;h3&gt;Phases III and IV:  Processing and Preservation&lt;/h3&gt;
&lt;p&gt;The processing and preservation stages of the lifecycle focus on &quot;actions or steps performed on data.&quot;
Rigorous documentation &quot;to ensure the utility and integrity of the data,&quot; as well as reproducibility,
is strongly recommended.&lt;a class=&quot;footnote&quot; href=&quot;#note_5&quot;&gt;5&lt;/a&gt; Common processing practices
include anonymization for things like medical data, merging two categories into one, tagging data
with attributes, normalizing spelling, etc. For book reviews, hand encoding
or correcting of metadata seems like most important thing to document.
If a data creator is going to use words like edition or format, it would be important to know if that
person has the bibliographical proficiency to use those terms accurately. On the computational side,
it is typical to do things like remove all punctuation from a text before generating a term frequency
list, so this kind of practice should be very well documented in anticipation of a less computationally
inclined audience.&lt;a class=&quot;footnote&quot; href=&quot;#note_6&quot;&gt;6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Under ideal circumstances, a &quot;readme&quot; or similar file should exist at a predictable endpoint so that
users otherwise unfamiliar with the data can learn more about it. The United States geological survey
data producers to assume that &quot;transfer may occur via automated or non-automated mechanisms&quot; (USGS).
In other words, datasets should be archived in a way that supports a human clicking a link to
download a set of files, as well as in a way that would allow a Python script to download all data
to a subdirectory.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src=&quot;/static/images/document.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The preservation stage typically begins with an understanding of when to preserve versus destroy
data. In a book history context, we are unlikely to destroy data but this consideration is required
in contexts where privacy is a chief concern. Here one typically considers the necessary context
for outside audience, how to best document practices, and how to articulate absence and uncertainties.
Perhaps most importantly, data makers must contextualize their data for humanities audiences that
is very familiar with well-known critiques of how other disciplines speak about or use data.&lt;/p&gt;
&lt;p&gt;Perhaps obviously, I do not think we should eschew the term data or rename it by some other key term.
I agree that skeptics of scientism are right to be skeptical, and I think scholars like
Lisa Gitelman and Virginia Jackson have raised important points about how positivism
mischaracterizes the primacy and autonomy of data.&lt;a class=&quot;footnote&quot; href=&quot;#note_7&quot;&gt;7&lt;/a&gt; Simultaneously, even the least quantitative
humanities scholarship is interspersed with what we might call pseudo-quantitative claims or
characterizations. To return to my opening example, I suspect that few would have a
problem looking at The New York Times book review like the one I showed you all and calling
it short. The point of comparing that review to others like it was to suggest that claims like
that one have quantitative consequences that might make one generalization more accurate than
another.&lt;/p&gt;
&lt;p&gt;When we make intuitive generalizations, a range of common missteps such as anchoring bias,
attentional bias, confirmation bias, and overconfidence are all potentially influencing what seems
like a straightforward judgment.&lt;a class=&quot;footnote&quot; href=&quot;#note_8&quot;&gt;8&lt;/a&gt; Positioning oneself against &quot;positivistic, strictly quantitative,
mechanistic, reductive and literal&quot; measures and methods has become increasingly prevalent in the
humanities, but the humanities have never abandoned our need to speak of external, observable
phenomena and divide those phenomena into legible units.&lt;a class=&quot;footnote&quot; href=&quot;#note_9&quot;&gt;9&lt;/a&gt;
Bibliographers and book historians are often quietly reminding literary studies scholars
that careful observation and tabulation lays the foundation for the close reading and
literary theory that imagines &quot;The Text&quot; as an independent, de-historicized, and de-materialized
object.&lt;/p&gt;
&lt;h3&gt;Conclusion: Phases V, VI, VIII: Distribution, Discovery, and Reuse&lt;/h3&gt;
&lt;p&gt;I have chosen to cluster distribution, discovery, and reuse for my conclusion because I see these
steps of the data lifecycle as a different way to interrogate data not &quot;as a natural resource but
as a cultural one that needs to be generated, protected, and interpreted.&quot;
&lt;a class=&quot;footnote&quot; href=&quot;#note_10&quot;&gt;10&lt;/a&gt; Distribution pertains to sharing one’s datasets
in a way that readers and especially other scholars can find and access.
It entails making one’s interpretive choices transparent, and demonstrating convincingly that
well-known techniques of distortion such as P-hacking have not been employed to reach a false result.&lt;/p&gt;
&lt;p&gt;A published article must cite its sources; ideally, a published article should also link to the
datasets used as evidence of its conclusions. Reproducibility is the first and most important
standard of distribution because a peer should be able to access data in a state that precedes
as many interpretive choices as possible, changes seemingly minor choices like removing all
punctuation or treating gothic fiction and ghost stories as members of the same category—and
observe how dramatically those changes affect the results.&lt;/p&gt;
&lt;p&gt;The timeliness of data releases should also be considered tremendously important because a work of
scholarship associated with a dataset likely contains the most rigorously constructed interpretation
of results for that dataset that will ever exist. Yet we should upload these data with the hope that
others will find our ideas fascinating and will want to reproduce our results, to interrogate our
findings, to build on our interpretations, to make our work stronger by criticizing it. And on that
note, I look forward to hearing your criticisms of this paper.&lt;/p&gt;
&lt;h3&gt;Notes&lt;/h3&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_1&quot;&gt;1. &lt;em&gt;Willa Cather: The Contemporary Reviews&lt;/em&gt;, edited
by Margaret Anne O’Connor, organizes Cather’s reviews by work reviewed rather than grouping them
by periodical of origin or placing them in chronological order.&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_2&quot;&gt;2. The faculty members with whom I worked are, Alison
Langmead, Benjamin Miller and Annette Vee. Graduate students Daniel Libertz and Lucia LoTempio
served as summer 2016 graduate student assistants on the project, and undergraduate Zach Luettgen
did an independent study on book reviews as networks in Spring 2017. &lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_3&quot;&gt;3. In addition to documenting the idiosyncratic
considerations of digitizing bibliographical objects like book reviews, our project has also focused
on best practices for data modeling and data curation when working with these materials.&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_4&quot;&gt;4. For example, Proquest’s American Periodicals Series and the HathiTrust collection.&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_5&quot;&gt;5. &quot;USGS Data Management - Data Lifecycle Overview.&quot;&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_6&quot;&gt;6. For examples of a range of data documentation practices,
see Ted Underwood, &quot;The Life Cycles of Genres&quot;; Katherine Bode, &quot;Thousands of Titles Without Authors:
Digitized Newspapers, Serial Fiction, and the Challenges of Anonymity&quot;; and Andrew Piper,
&quot;Fictionality.&quot;&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_7&quot;&gt;7. See Gitelman, &lt;em&gt;Raw Data Is an Oxymoron&lt;/em&gt;.&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_8&quot;&gt;8. Anchoring is the tendency to overvalue a particular trait.
Attention bias is the tendency to be affected by recurring thoughts. Confirmation bias describes a
tendency where the &quot;selection and evaluation of information that would confirm a focal hypothesis
is given priority—or even exclusivity&quot; (Rajsic, Wilson, and Pratt, &quot;Confirmation Bias in Visual
Search,&quot; 1353). Overconfidence is a tendency to overvalue one’s own answers to questions, which
might in turn prevent someone from taking a measurement or consulting an outside source.&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_9&quot;&gt;9. Drucker, &quot;Humanistic Theory and Digital Scholarship,&quot; 86.&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_10&quot;&gt;10. &quot;Overview,&quot; press materials for &quot;Raw Data Is an Oxymoron.&quot;&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://matthew-lavin.com/blog/computational-cather/">
    <title type="text">Computational Methods in Authorship Studies</title>
    <id>urn:uuid:d8c0ff25-c5cd-3599-b2a0-4f5ab0508d55</id>
    <updated>2017-09-06T00:00:00Z</updated>
    <link href="http://matthew-lavin.com/blog/computational-cather/" />
    <author>
      <name>Matt Lavin</name>
    </author>
    <content type="html">&lt;p&gt;&lt;em&gt;What follows is a copy of my remarks from a talk at Duquesne University in February 2017. I wanted to share these now because
I'm starting to think once again about the topic I discussed and I wanted to revisit past work before moving forward. Where
necessary, I've added images from the accompanying slideshow.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Good afternoon, and thank you for having me (and especially thanks to Linda Kinnahan, Elaine Parsons, Mary Parish for doing the
work it takes to put this event together). I would like to begin today not with the digital humanities, but by situating myself
in relation to two overlapping though often wholly disparate scholarly concepts: studies of a single author (in my case
&quot;Cather studies&quot;), and the study of authorship or authorship history. Scholarship focused on a single author is perhaps less
common in an English department than it was thirty years ago, but it is by no means a thing of the past. Its position or
credibility, I believe, has greatly depreciated. Any number of factors might separate one single-author scholar from another,
yet the idea of being too narrowly focused, or too invested in authorial intent, or too biographical are all potential points
of criticism.&lt;/p&gt;
&lt;p&gt;Authorship history, in contrast, is perhaps best described as a subfield of the history of the book, also called book history or
book studies. Book history generally focuses the inception, production, publication, circulation, and reception of any written and
printed material, including but limited to books. Descriptive bibliography, which underpins the discipline, is concerned with the
precise description of books as physical objects. These approaches differ from, say, biographical criticism or literary history in
both topical focus and methodology, although all of the subfields I've mentioned have points of intersection. We move from the
study of one author to the study of authorship when we take on topics like copyright, literary celebrity, or the origin of
authorship as a profession, as do Martha Woodmansee, Loren Glass, and Leon Jackson respectively. Single-author case studies are
common in this subfield; type &quot;authorship&quot; with Twain, Whitman, or Wharton, and you will see many results. The shared element in
these studies is emphasis on the institution behind an author rather than the author as an individual.&lt;/p&gt;
&lt;p&gt;In contrast, you would have a harder time finding a computational analysis of the history of authorship. As Matthew Kirschenbaum
and Sarah Werner argued in the 2014 &quot;State of the Discipline&quot; essay for &lt;em&gt;Book History&lt;/em&gt;, the distant reading or big data
trend &quot;is not one that has spoken to book historians&quot; (410). A search for that approach would likely lead you to authorship
studies or authorship attribution, which differs significantly for historical approaches to authorship. Those interested in large
scale computation have focused on formalistic questions like the meaning of genre or the verbal architecture of a plot, and book
historians, by and large, have focused on other areas of digital humanities, such as scholarly editing, media archeology, or
digital projects development. The analytics-driven subset I am talking about differs from these other clusters of practitioners
in significant ways. However, I will save most of these kinds of distinctions for later in this presentation.&lt;/p&gt;
&lt;p&gt;In this talk, I will focus on some computational methods that seem particularly important to authorship studies and book history,
and I will use Cather as a central frame. My aspiration is to do justice to Cather and yet make gesture to topics that might
apply to many authors in many different contexts. I believe that many of these methods will also have implications for scholarship
focused on a single author because large scale analytics can intervene in some of the classic problems that arise when scholars
like me try to navigate the fuzzy periphery where studying a single author becomes the study of authorship, and vice versa.&lt;/p&gt;
&lt;p&gt;I will elaborate and (I hope) clarify what I mean with an example. In 2012, I defended a dissertation called &quot;Collaborative
Momentum: The Author and the Middle Man in U.S. Literature and Culture, 1890-1940,&quot; which traced the role of agents, editors,
publishers, and other literary go-betweens in constructing modern authorial credibility. This dissertation, like so many others,
was a collection of case studies, each focused on one particular author or text. My second chapter focused on Willa Cather's role
in ghostwriting S.S. McClure's My Autobiography. In fall of 2012 or so, I excerpted and revised this chapter as an article for
submission and was rejected several times, in part because my work was described as too narrowly focused on a single author. I
revised the article substantially, and it appeared in &lt;em&gt;Auto|Biography Studies&lt;/em&gt; last year.&lt;/p&gt;
&lt;p&gt;As I've mentioned, the single-author case study is a well-accepted unit of analysis in literary studies and book history. Loren
Glass's &lt;em&gt;Authors, Inc.&lt;/em&gt; has chapters like &quot;Trademark Twain&quot; and &quot;Legitimating London.&quot; Meredith McGill's &lt;em&gt;American
Literature and the Culture of Reprinting&lt;/em&gt; has &quot;Suspended Animation: Hawthorne and the Relocation of Narrative Authority.&quot;
(Alliteration and puns are encouraged but not required.) The question for me is where a case study begins to lose its emphasis
on representing a wider scope than the discrete subject at hand. It's easy to begin with a question like &quot;how did Cather's
collaboration with McClure exemplify and/or differ from emergent norms for ghostwriters and instead become preoccupied with
the not-totally-unrelated question, &quot;Did Cather respect and care about S.S. McClure?&quot;&lt;/p&gt;
&lt;p&gt;I'm not the first to face this tension. Numerous scholars have written about Cather's role in the making of this book. Sharon
O'Brien's biography of Cather emphasizes that the author's coming of age required outgrowing her role as &quot;the deferential
daughter to two fathers,&quot; Henry James, her aesthetic father, and McClure, her professional father (288), in order to move from
McClure's editor to a novelist of national significance. Robert Thacker, responding to O'Brien, argues that Cather's &quot;gift of
sympathy&quot; was the major force behind her participation—&quot;That is, she wrote it as a favor and out of gratitude for all he had done
for her since their first meeting in 1903&quot; (126). O'Brien and Thacker have largely biographical emphases, though both make
connections to Cather's emerging literary aesthetic.&lt;/p&gt;
&lt;p&gt;Deborah Lindsey Williams and Emmy Stark Zitter offer close readings of &lt;em&gt;My Autobiography&lt;/em&gt; aimed at exposing Cather's
subjectivity in its narrative voice. Williams identifies textual signs of Cather deploying the ghost as a kind of &quot;open secret&quot;
paralleling her own queerness, and Zitter interprets traces of a writer empowering herself by taking on and eventually turning
away from the voice of a male narrator.&lt;/p&gt;
&lt;p&gt;My goal with &quot;Reciprocity and the Real Author&quot; was to focus on Cather as a case study of &quot;collaboration against the backdrop of
ghostwriting as an emerging profession and against the strong historical connections between ghostwriting and autobiography.&quot;
I felt the need to McClure's motives for planning an autobiography and Cather's motives for serving as ghostwriter, as well as
the degree to which My Autobiography was initially produced as a serial narrative for McClure's Magazine. I argued that McClure
and Cather's collaborative work consistently straddled distinctions between economic and symbolic capital; that a neither a
strictly economic nor a strictly biographical analysis would demonstrate the complex ways in which economic capital and credibility
 interacted with each other during a period when ghostwriting itself was transforming but not yet fully transformed into a
 market-dominant set of norms. For me, the experience of working on McClure's autobiography demonstrated the concrete ways that
 the study of one author and the study of authorship blur and mix but simultaneously urge a scholar in different directions.&lt;/p&gt;
&lt;p&gt;Sometime during my revisions for this article, Duquesne's Patrick Juola came to the University of Nebraska, where I was a
postdoctoral fellow, and gave a talk about authorship attribution. Though it carries the keyword authorship, this field is
significantly different from what I have described so far as authorship studies. Authorship attribution is perhaps best described
as the statistical (and now, almost always computational) analysis of text to determine its most probable author. It can be
regarded as a subcategory of stylometry (quantitative analysis of style) or digital humanities or humanities computing, but many
of its best practitioners are in computer science departments rather than English or history departments.&lt;/p&gt;
&lt;p&gt;Using authorship attribution methods to think about Cather as a ghostwriter seemed immediately promising. O'Brien and Thacker
take opposing positions about Cather's motivations but share the perspective that her voice in McClure's autobiography makes
its way into her later fiction. Williams and Zitter argue that Cather was more successful making her narrator sound like McClure.
The autobiography is most commonly associated with My Antonia (1918) and The Professor's House (1925) because both have strongly
autobiographical structure and content.  All four see continuity between the autobiography and Cather's later fiction, where a
generation of scholars before them regarded the autobiography as hack work, or a rush job, or something base that showed little
signs of being written by Cather at all. Authorship attribution cannot settle this disagreement, but it can provide new
information to evaluate how extensively Cather changed her writing style to take on McClure's identity for the project, and
perhaps contribute to a larger conversation about how well any ghostwriter can fake another person's voice.&lt;/p&gt;
&lt;p&gt;Here I feel the need to articulate some self-awareness. I am white man speaking about the intersection of a woman's personal
relationships with her emergent professional and authorial identity. To some, I might seem like a smart-aleck entering a
humanistic debate by saying: &quot;Actually, I've studied this issue with a computer program, and you're all wrong.&quot; Instead, what
I'd like to do is use authorship attribution as one way (among many) to think about the ways of knowing that historicism,
hermeneutics, and quantitative analysis can enable respectively and in tandem.&lt;/p&gt;
&lt;p&gt;To do this, I constructed a study to compare Cather's writing against McClure's writing and see which was a better fit for &lt;em&gt;My
Autobiography&lt;/em&gt;. Cather wrote lots of things—nonfiction and fiction—so it was easy to find comparison texts by her. A few years
after the autobiography appeared in print, McClure wrote and published a work of nonfiction called &lt;em&gt;Obstacles to Peace&lt;/em&gt;.
Using head-to-head tests, I compared Obstacles to Peace to various works by Cather, in each case using &lt;em&gt;My Autobiography&lt;/em&gt;
as the point of comparison. Beyond this, I was curious to see which of Cather's writings would register as most similar to the
autobiography. I also wanted to run analyses on the magazine version of the novel and the book version, which McClure is said to
have revised for publication without Cather's assistance. For the magazine, I analyzed each installment separately to see if
Cather was more visible in any particular segment, which is a way of investigating the possibility that Cather wrote some
installments but not others. I used a method called &quot;Burrow's Delta,&quot; (more on this in a moment) and hypothesized that the test
would easily identify Cather as the author of the autobiography.&lt;/p&gt;
&lt;p&gt;In authorship attribution tests, especially in a &quot;closed set&quot; problem like this one—two candidates, one disputed text—the
author's identity can be successfully determined with impressive accuracy, sometimes as high as 90-95%. Most authorship
attribution methods look closely at how frequently a text uses high frequency function words, words that are so common
to the English language that it's almost impossible for someone to modulate deliberately how often they appear. These are words
like &quot;the,&quot; &quot;of,&quot; &quot;as&quot; and &quot;in.&quot; They are not associated with any particular context or topic (unlike, say, &quot;fish&quot; or &quot;tree&quot; or
&quot;prayer&quot; or &quot;shovel&quot;) and they can be found in any text of sufficient length in the English language. Burrow's Delta is a little
different in that it constructs a word list based on the most frequent words in common among the candidates and test text, but
this almost always produces a comparison set of function words because they are the most frequently used words in English.
My sense of how authorship attribution would perform in the face ghostwriting was that even a text that very successfully
replicated the qualitative or affective experience of another person's manner of speaking would read, to a computer, as an
obvious fake.&lt;/p&gt;
&lt;p&gt;My findings were consistent with the initial conjecture. On the surface, the results of this study are quite clear, yet they may
also suggest some deeper implications. I ran several versions of Burrows Delta, with various small changes to the settings
(changing the number of function words analyzed, and changing sample sizes, two different ways of controlling for text length)
and found that my tests predicted Cather to be the more probable author of the autobiography. For book serial as a whole, Cather
won 24 head-to-heads, McClure won zero. In one test for installment 8 and two tests for installments 2, 4 and 6, McClure surpasses
Cather's &quot;Three American Singers.&quot; These are McClure's only victories in the entire set, and can be viewed as statistical
outliers. (I think it would be more suspicious if he didn't win any head-to-heads.) Further:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cather texts of various genres, dates, and lengths win over Obstacles to Peace&lt;/li&gt;
&lt;li&gt;Results hold true for serial and books version, using culling=0 and culling=100&lt;/li&gt;
&lt;li&gt;Mean margins of victory for book version are slightly smaller than magazine version, but not significant enough for me to link them to any specific edits.&lt;/li&gt;
&lt;li&gt;Any changes McClure made to the book version of the autobiography were not extensive enough to swing the results of these tests to him.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The autobiography's authorial signal matching Cather's is consistent with biographical and archival sources, both of which suggest
that McClure supplied subject matter for his autobiography, whereas Cather was the only person known to have put pen to paper for
the serial version.&lt;/p&gt;
&lt;p&gt;The matter of Cather's probable authorship is rather uncontroversial, which is in itself a very substantive finding, as it provides
something of an initial affirmation for scholars like me who were sure she wrote the thing. Perhaps more interesting, however,
were my results for individual installments and individual head-to-heads. Since Cather was the more likely candidate in so many
head-to-head comparisons, these images depict the margin of difference between Cather and McClure, a greater margin suggesting
(simplistically) more similarity between the autobiography and a Cather text. The images below show that Cather's margins are
highest for the first and second installments and lowest at the very end of the autobiography.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src='/static/images/serial_margins_cull_100_labels.png' /&gt;&lt;/p&gt;
&lt;p&gt;Figure 1: Authorial signal margins by installment for &lt;em&gt;My Autobiography&lt;/em&gt; serialization,
comparing most frequent words, but only when words are found in all compared texts.
(The higher a line is along the Y axis, the more clearly that novel matches &lt;em&gt;My Autobiography&lt;/em&gt;'s style)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src='/static/images/serial_margins_no_cull_labels.png' /&gt;&lt;/p&gt;
&lt;p&gt;Figure 2: Authorial signal margins by installment for &lt;em&gt;My Autobiography&lt;/em&gt; serialization,
comparing most frequent words, regardless of whether they are found in all compared texts.
(The higher a line is along the Y axis, the more clearly that novel matches &lt;em&gt;My Autobiography&lt;/em&gt;'s style)&lt;/p&gt;
&lt;p&gt;In terms of Cather texts most similar (by this measure) to &lt;em&gt;My Autobiography&lt;/em&gt;, I have used histograms to show the top six
margins of victory in all my various head-to-heads. I'm presenting four versions of this top six list:&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src='/static/images/top_six_serial_cull_100_labels.png' /&gt;&lt;/p&gt;
&lt;p&gt;Figure 3: Top Six Margins. Serial Version. Function Words Not Present in All Three Texts Ignored (cull=100). Margins of Difference Scaled to Delta.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src='/static/images/top_6_serial_no_cull_labels.png' /&gt;&lt;/p&gt;
&lt;p&gt;Figure 4: Top Six Margins. Serial Version. No Function Words Ignored (cull=0). Margins of Difference Scaled to Delta.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src='/static/images/top_6_book_cull_100_labels.png' /&gt;&lt;/p&gt;
&lt;p&gt;Figure 5: Top Six Margins. Book Version. Culling.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;slide&quot; src='/static/images/top_6_book_no_cull_labels.png' /&gt;&lt;/p&gt;
&lt;p&gt;Figure 6: Top Six Margins. Book Version. No Culling.&lt;/p&gt;
&lt;p&gt;Taking these results as a whole, we can see that Cather's &quot;Training for the Ballet,&quot; &lt;em&gt;My Antonia&lt;/em&gt;, &lt;em&gt;The Professor's
House&lt;/em&gt;, and &lt;em&gt;Obscure Destinies&lt;/em&gt; are found in the top six margins of victory for all four versions of the test. &lt;em&gt;Lucy
Gayheart&lt;/em&gt; and &quot;Plays of Real Life&quot; both rank in the top six margins of victory in two our of four tests. &lt;em&gt;O Pioneers!&lt;/em&gt;,
&lt;em&gt;Shadows on the Rock&lt;/em&gt; and &lt;em&gt;Not Under Forty&lt;/em&gt; each appear in one top six list, and other works like &lt;em&gt;Alexander's
Bridge&lt;/em&gt;, &lt;em&gt;Death Comes for the Archbishop&lt;/em&gt;, &lt;em&gt;My Mortal Enemy&lt;/em&gt;, and &lt;em&gt;A Lost Lady&lt;/em&gt; do not ever appear in
the top six margins of difference.&lt;/p&gt;
&lt;p&gt;Although it can be notoriously difficult to assign causality to the result of an authorship attribution test (or, in fact, to
assign causality to any correlation), I find it suggestive that My Antonia and The Professor's House have strongly
autobiographical structures. The strength of their margins over Obstacles to Peace could relate to their use of the first-person
but, if that were the case, I would expect to see My Mortal Enemy (also first person) in the top tier.&lt;/p&gt;
&lt;p&gt;A logical next step here that I have yet to perform would be to run Burrows Delta on a setting that deliberately ignores personal
pronouns like I, me, him, he, her, she and they. Additionally, I would like to cross-validate the results of the Burrows Delta
test using two well-known authorship attribution techniques: logistical regression of high frequency function words and
chi-squared testing. Each of these methods has pros and cons but, for my purposes, I'm most concerned with whether the results of
these methods will be consistent with the Burrows Delta result, especially in terms of the higher margins of difference for
particular texts by Cather. Additional next steps would include, foremost, expanding the McClure corpus to break the study's
dependence on &lt;em&gt;Obstacles to Peace&lt;/em&gt;. McClure authored very few texts, but some of his personal letters could be transcribed and
analyzed using these methods. Cather's letters should be added to the comparison to create analytical parity.&lt;/p&gt;
&lt;p&gt;Perhaps more significant than any immediate next steps, however, would be some consideration of how a case study like this one can
be built upon in a way that informs the humanistic study of authorship or cultures of letters. Immediate research questions
related to what I've done so far might include a broader inquiry into how well ghostwriters throughout history imitated their
subjects' authorial tendencies. If we can establish norms for ghostwriters, perhaps we can use anomalous results to isolate cases
where an autobiographical subject has more of a co-authorship role. Going further, I would like to use these methods to think
critically about anonymity in nineteenth-century periodicals, pseudonyms in pulp fiction, and various models of authorial
collaboration.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is point marks the end of my remarks from the talk but there's a bit more to what I want to share. Everything below
this block of italics I wrote this Fall.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This piece, like so much of what I do, is unfinished work.&lt;/p&gt;
&lt;p&gt;Part of my task for that February day almost nine months ago was to queue up an interactive workshop, so the rest of the text
pertains to that subject. I went on to try and show, by example, some of the computational methods that I think are best suited
for building on a case study like mine in a way that puts pressure on the history of anonymity or ghostwriting or the
humanistic study of authorship or a culture of letters.&lt;/p&gt;
&lt;p&gt;What I basically let hang was a more theoretical or generalized discussion of this same topic. The extent to which I moved away
from such musing is very clear to me now as I re-read, but it was less clear at the time. I suppose I thought the question was
provocative even without an  initial response.&lt;/p&gt;
&lt;p&gt;What I think I alluded consistently in the piece is the idea that authorship studies, like computational analysis, lives and dies by the
finding of facts. Book historians and bibliographers, map-makers and chronologists and scholarly editors must believe to one
extent or another in the primacy and relative autonomy of external phenomena. This is the basis for historical observation, as well as
quantitative analysis. Observations can and must be complicated, situated, contextualized, and questioned. I am a lover of
irreverence, and I instinctively mistrust an authority figure pressing Truth down upon me like a cover stamp. Nevertheless,
the question of Cather's role in McClure's autobiography has a basis in the empirical, and some positions with regard to that
question are simply more accurate than others. The book historian/bibliographer and the computational humanist share a love for
observation and a need to complicate our observations, and this I think is the initial basis for computational
book history/bibliography, which includes computational authorship studies.&lt;/p&gt;
&lt;p&gt;One problem with the fact people in literary studies is that so many of their observations have been superficial distortions
of observable phenomena. In the author-centered literary studies of old, the Author always seems to work alone. The Author has read everything.
The Author was always own course to writing her magnum opus. The Author did not lie in letters. The Author didn't get ideas from
cheap paperbacks by Edward Bulwer-Lytton or Zane Grey. The Author won every fight and rerouted the river to clean the Augean
Stables. Some fear a return to author-centered scholarship precisely because this specter looms in the distance. I believe that
computational authorship studies can help us turn away from myths and bring us closer to discussions of norms and exceptions.&lt;/p&gt;
&lt;p&gt;Others fear something a colleague of mine called minutia. I think what he was meaning to say is that single author scholars
often get so good at looking at a tree that they forget there's a forest. This worry has less to do with the study of authorship
than the study of a single author, but both are capable of descending into minutia, as I probably did numerous times in my dissertation.
In my February talk, I put this perhaps more delicately. I spoke of &quot;where a case study begins to lose its emphasis on
representing a wider scope than the discrete subject at hand.&quot; Either way, I believe computation can help with this tension.&lt;/p&gt;
&lt;p&gt;So far I'm imagining three &quot;next steps&quot; toward a more developed community of computational book history/bibliography.
The first step, I think, is learning to write computational research questions. That's what interactive workshop after
my February talk was about. We need to think in terms of questions that computing can answer, or at least help us address.&lt;/p&gt;
&lt;p&gt;Second, to write computational research questions (or computationally compatible research questions), we must reckon with
big questions of empiricism and quantification. I doubt we will resolve our ambivalence about empirical phenomena any time soon,
but I believe we must confront it openly.&lt;/p&gt;
&lt;p&gt;Third and finally, we must build a culture of open data. As book historians, we can talk about copies printed,
list prices, title variations across editions, people named in various acknowledgments, or any number of areas of
inquiry that require better data. One day we might even have data showing whether ghost-writtten
texts &lt;em&gt;typically&lt;/em&gt; resemble the ghostwriter's style more than the autobiographical subject.
Publishing web-based resources is not enough; we must enable computational access to the data we make.&lt;/p&gt;
&lt;p&gt;We must teach book historians to make data, to interrogate data, to make use of other scholars' data, and to
share data. These practices need to become prerequisites for computational humanities, and they could be an
effective rallying point for computational book history/bibliography.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://matthew-lavin.com/blog/neologophobia/">
    <title type="text">Diagnosis: Neologophobia</title>
    <id>urn:uuid:f683ee93-e34a-394e-a62c-6f848991c5f8</id>
    <updated>2017-06-01T00:00:00Z</updated>
    <link href="http://matthew-lavin.com/blog/neologophobia/" />
    <author>
      <name>Matt Lavin</name>
    </author>
    <content type="html">&lt;h3&gt;A Provocation&lt;/h3&gt;
&lt;p&gt;With the spring semester over, I've been coming back to a project I haven't worked on in almost a year.
It originated with my collaboration with Alex Gladwin and Dan Look on H.P. Lovecraft's role in revising C.M. Eddy's
&quot;The Loved Dead.&quot; Sometime during that collaboration, Dan mentioned to us that Lovecraft had said in a letter that
he didn't tend to use words in his writing that had come into the English language more recently.&lt;/p&gt;
&lt;p&gt;At the time, I had read Ted Underwood's article on &quot;The Emergence of Literary Diction,&quot; and I was immediately interested
in whether a computational approach could look closer at Lovecraft's use (or not) of neologisms and or archaisms.
At Keystone DH in June 2016, I presented a solo conference paper on some of the work I'd done to interrogate this subject,
especially focusing on how to measure a single author's use of neologisms. The summer, however, was short, and I found myself
scrambling to finish my fall syllabi before I'd had the chance to work on adapting the conference presentation into
an article.&lt;/p&gt;
&lt;p&gt;Before I say more about what I did in this presentation and what I am doing for the article, let me back up and say that,
some time between the initial conversation with Alex and Dan and the conference paper, I asked Dan to help me find the original
letter he was talking about. He provided two letter citations, both found in &lt;em&gt;H.P. Lovecraft Selected Letters&lt;/em&gt;,
but the first of them, Lovecraft to Maurice W. Moe, January 1, 1915, really got me excited:&lt;/p&gt;
&lt;blockquote&gt;
The books which are used were not modern reprints, but musty old volumes written with &quot;long s'ses.&quot; By some freak of
childish perversity, I began to use long s's myself, and to date everything two centuries back. I would sign myself
&quot;H. Lovecraft, Gent., 1698&quot;, etc. Latin came quite naturally to me, and in other studies my mother, aunts, and grandfather
helped me greatly. ... When I was ten I set to work to delete every modern word for my vocabulary, and to this and I
adopted an old Walker's dictionary (1804) which was for sometime my sole authority. All the Queen Anne authors combined
to form my literary diet. (qtd. in Derleth and Wandrei, 5-6)
&lt;/blockquote&gt;&lt;p&gt;A consider this letter a provocation of sorts. The literary biographer wonders simply how accurate Lovecraft's narrative of
self-fashioning could be. Is it possible to read so much from an historic period that one's prose begins to look and feel like
a throwback? Is it possible to use an historic dictionary to purge one's writing of neologisms? And if so,
why would you want to do that? In this blog post, I will unfortunately answer none of these questions, as most of them are
the heart of the article I'm working on. Instead, I'm going to focus on one particular computational method that I've been
working on to describe an author's relationship with their historical moment: a linear regression algorithm to predict a text's
year of origin.&lt;/p&gt;
&lt;h3&gt;Defending an Over-the-Top Blog Title&lt;/h3&gt;
&lt;p&gt;What is neologophobia? If you ask the Google machine, it might reply: &quot;Did you mean: monologophobia&quot;? Monologophobia is,
I just learned, is &quot;A fear of using a word more than once in a single sentence or paragraph.&quot; However, if you look up
the Greek origin of the terms &lt;em&gt;philia&lt;/em&gt; and &lt;em&gt;phobia&lt;/em&gt;, I believe that you will find them to be antonyms.
-Philia and -phile refer to abnormal attraction or a tendency toward, and -phobia and -phobe refer to abnormal
repulsion (fear, hate) or a tendency against. It is with this definition in mind that I am using the term neologophobia:
an abnormal aversion or tendency away from neologisms.&lt;/p&gt;
&lt;h3&gt;Stylochronometry: Because Big Words Are Fun&lt;/h3&gt;
&lt;p&gt;I don't want to do an extensive literature review here, but the study of a text's date signature is not new. Some
have been interested in questions like &quot;when did Shakespeare most likely write [name your play]&quot; or &quot;which came first? novel
A or novel B?&quot; The idea that a text contains information about its approximate date in history is a bit more recent, or maybe
it's just become more prominent with the rise of machine learning methods.&lt;/p&gt;
&lt;p&gt;I should mention that I emailed with Ted Underwood about a year ago about date prediction, and he suggested that
I look into machine learning, especially linear regression, as a text's publication date is considered continuous data,
which is to say that the year 1785 is more related to 1786 than 1800 whereas, in a classification task like sentiment tagging,
&quot;happy&quot;, &quot;sad&quot;, &quot;afraid&quot; and &quot;angry&quot; are all equally related to one another. &lt;a href=&quot;http://www.differencebetween.com/difference-between-classification-and-vs-regression&quot;&gt;This page&lt;/a&gt; has a better summary.&lt;/p&gt;
&lt;p&gt;I was very new to machine learning at the time, and I was grateful for the nudge in
the right direction. I did a bit of classification for Keystone DH 2016, but I put it aside with everything else
when school started last fall. My next big nudge was meeting David Bamman when he came to Pittsburgh to give a talk.
I missed his talk (for a dissertation defense) but got to talk to him later that day. I later found his article, &lt;a href='http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/jcdl2017.pdf'&gt;&quot;Estimating the Date of First Publication in a Large-Scale Digital
Library&quot;&lt;/a&gt;, which is the best work on this topic I've found.&lt;/p&gt;
&lt;p&gt;Bamman et. al. ultimately conclude that &quot;the best method for estimating the date of first publication for books in a
large digital library is to leverage the depth of the collection, identifying duplicates and assigning the first date of
publication for a book to be the earliest date attested among its near-duplicates&quot; (6). However, this assertion pertains specifically
to the information retrieval or quality assurance aspect of their work. They add:&lt;/p&gt;
&lt;blockquote&gt;
Even though our estimates of the true first date of publication are better served with deduplication-based methods,
learning a model to predict this date from the content of the book gives us the potential for deeper insight into the
books in our collection by providing a mechanism for measuring apparent time, as distinct from both the observed
publication date or the narrative time. (8)
&lt;/blockquote&gt;&lt;p&gt;In other words, an added bonus of employing machine learning methods rests in the way the model relates to its outliers.
In a linear regression model in particular, the you're essentially drawing a line (or a multi-dimensional vector)
designed to accurately predict a variable based on inputs. Given the input of a text's term frequencies, a well-trained
model can produce a reasonably accurate prediction of that text's likely date of inception.&lt;/p&gt;
&lt;p&gt;However, there are always outliers, texts whose predicted date is way off from its actual date. If you're in QA, you might use
this outlier status to flag a text for a possible metadata error (Bamman et. al. 7). Once a date error has been ruled out, however,
we must consider the notion that a text whose predicted date differs from what its term frequencies suggest might do so
because its textual features defy the norms of its historical period.&lt;/p&gt;
&lt;h3&gt;Dataset and Some Code&lt;/h3&gt;
&lt;p&gt;Around May of 2016, I was putting a lot of energy into how I might create a dataset to compare Lovecraft's &quot;date signal&quot; to
other authors of interest. Then I came upon Ted Underwood's &quot;The Lifecycles of Genres&quot; and realized that he'd shared publicly
a dataset that I could use for my work and easily build upon. As a result, the methods I've been playing with are tested on
this corpus of general metadata, genre tags (science fiction, crime/mystery, gothic/horror and non-genre) and term frequency
tables for more than 950 novels. Here's &lt;a href=&quot;https://github.com/tedunderwood/fiction&quot;&gt;the repo&lt;/a&gt;. I was also able to use the same codebase for a conference paper on genre analysis at the
&quot;How to Do Things with Millions of Words&quot; conference in November 2016.&lt;/p&gt;
&lt;p&gt;Ted also shared his code. It focuses on using a logistic regression to make genre predicts, so it needed some adapting.
I focused my edits on two fronts: designing my own tests and adding features that would make the code run faster.
The first way I thought to speed it up was to take a block of code that imports term frequency tables and store that data so
that you don't need to rerun it every time you run a regression. Reading many text files is an infamously memory-intensive
process.&lt;/p&gt;
&lt;p&gt;You can get some major memory benefits using a datastore (mysql, psql, redis, etc.) but, after a lot of playtime, I opted to
load the data as a series of Python pickles, which are surprisingly efficient. Here's what some of that code looks like:&lt;/p&gt;
&lt;pre&gt;
import pickle
import csv

dict_of_10k = {}
with open (&quot;lexicon/new10k.csv&quot;, &quot;r&quot;) as myfile:
    for m_line in csv.reader(myfile):
        if m_line[0] != &quot;word&quot;:
            dict_of_10k[m_line[0]] = m_line[1]

docids = []
with open (&quot;meta/finalmeta.csv&quot;, &quot;r&quot;) as myfile:
    for m_line in csv.reader(myfile):
        if m_line[0] != &quot;docid&quot;:
            docids.append(m_line[0])

full_feature_dicts = []
feature_dicts = []
excluded_ids = []
for _id in docids:
    try:
        full_fdict = {}
        fdict = {}
        with open(&quot;newdata/%s.fic.tsv&quot; % str(_id)) as f:
            s = f.read()
            s = s.replace(&quot;\n\&quot;\t&quot;, &quot;\n\\\&quot;\t&quot;)
            row = s.split(&quot;\n&quot;)
            cells = [tuple(i.split(&quot;\t&quot;)) for i in row]
            for y in cells:
                try:
                    full_fdict[y[0]] = int(y[1])
                except:
                    pass
                #check for top 10k terms
                try:
                    test = dict_of_10k[y[0]]
                    fdict[y[0]] = int(y[1])
                except:
                    pass
        full_feature_dicts.append(full_fdict)
        feature_dicts.append(fdict)
    except:
        print(_id)
        excluded_ids.append(_id)

pickle.dump(feature_dicts, open( &quot;pickled_data/feature_dicts_10k.p&quot;, &quot;wb&quot; ))
pickle.dump(full_feature_dicts, open( &quot;pickled_data/full_feature_dicts.p&quot;, &quot;wb&quot; ))
pickle.dump(excluded_ids, open( &quot;pickled_data/excluded_ids.p&quot;, &quot;wb&quot; ))
&lt;/pre&gt;&lt;p&gt;I use similar scripts to load metadata and genre tags, but the term frequency feature data is where you make all your gains
in terms of efficiency. This part of code takes several minutes to run but, now that you have your data
saved as a set of pickles, you can load those files instead of reloading and reprocessing the text files
every time you run a regression.&lt;/p&gt;
&lt;h3&gt;C10H15N + OD = Method? (That Title is the Worst Joke I've Ever Thought Of)&lt;/h3&gt;
&lt;p&gt;So far, in one form or another, I've played with characterizing a text's date by looking at its Germanic-Latinate word origin ratio (using dictionary.com word origin data
from Underwood and Sellers' work and a scraped dataset from the OED Online); calculating a &quot;Walker ratio&quot; by seeing how many words in a text are also in an OCRed version of
&lt;em&gt;Walker's Dictionary&lt;/em&gt;, and various machine learning methods, including linear regression. In this version of the code,&lt;/p&gt;
&lt;p&gt;Whenever you run a supervised learning model, it's typical to partition your dataset into a training set and test set.
You train the model one partition (term counts and dates) and test your data on the other partition, feeding it only term counts
and generating predicted dates. You can then compare the predicted dates to the labeled dates for your test set to see
how accurate your model is. My code achieves this task by generating 500 random numbers to indicate which texts will be in the training
set.&lt;/p&gt;
&lt;pre&gt;
from random import shuffle
import pickle
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction import DictVectorizer
from sklearn.linear_model import LinearRegression

#load 10k feature dicts and metadata
metadata = pickle.load( open( &quot;pickled_data/metadata.p&quot;, &quot;rb&quot; ) )
feature_dicts = pickle.load( open( &quot;pickled_data/feature_dicts_10k.p&quot;, &quot;rb&quot; ) )

def predict_years(metadata, feature_dicts):

    all_years = [int(i[8]) for i in metadata]
    all_ids = [i[0] for i in metadata]
    myrange = list(range(0, len(metadata)))
    shuffle(myrange)

    randoms = myrange[:500]
    randoms.sort()

    #define train_years, test_years
    train_years = []
    test_years = []

    #define train_dicts, test_dicts
    train_dicts = []
    test_dicts = []

    train_ids = []
    test_ids = []

    for num in myrange:
        if num in randoms:
            train_years.append(all_years[num])
            train_dicts.append(feature_dicts[num])
            train_ids.append(all_ids[num])
        else:
            test_years.append(all_years[num])
            test_dicts.append(feature_dicts[num])
            test_ids.append(all_ids[num])

    #print(len(train_years) == len(train_dicts))
    #print(len(test_years) == len(test_dicts))
    train_ids_str = &quot;, &quot;.join(train_ids)
    test_ids_str = &quot;, &quot;.join(test_ids)

    #use scikit learn Pipeline functionality to vectorize from dictionaries, run tfidf, and perform linear regression
    text_clf = Pipeline([('vect', DictVectorizer()), ('tfidf', TfidfTransformer()),('clf', LinearRegression()),])
    text_clf = text_clf.fit(train_dicts, train_years)
    predicted = text_clf.predict(test_dicts)

    result_rows = []
    margin = []
    for i,j in enumerate(predicted):
        m = abs(j - test_years[i])
        margin.append(m)
        row = [test_ids[i], j, test_years[i], m]
        rows.append(row)

    mean = np.mean(margin)
    main_row = [test_ids_str, train_ids_str, mean]
    return (main_row, result_rows)
&lt;/pre&gt;&lt;p&gt;Once you've run the regression, it's probably a good idea to store your results for later use.
One way to do that is with csv or Microsoft Excel output, as these are widely used and easy-to-access
output formats. Another way to go is to make a simple sqlite database. Sqlite3 is built into Python
and is very easy to use. It's also another area of performance optimization, as an sqlite storage engine
will increase retrieval speed when you go back to your results for analysis or visualization. Third,
you gain all the same interoperability benefits you would get from using a format like .csv, as it's very
easy to load sqlite in R and other programming languages. Here's a function that takes linear regression results
stores them in two sqlite tables:&lt;/p&gt;
&lt;pre&gt;
import sqlite3

def store_results(main_row, result_rows):
    conn = sqlite3.connect('regression_scores.db')
    c = conn.cursor()
    make_main = &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS main (id INTEGER PRIMARY KEY, test_ids TEXT, train_ids TEXT, mean_margin REAL)&quot;&quot;&quot;
    c.execute(make_main)
    make_results = &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS results (id INTEGER PRIMARY KEY, main_id INTEGER, doc_id TEXT, predicted REAL, actual REAL, margin REAL, FOREIGN KEY(main_id) REFERENCES main(id))&quot;&quot;&quot;
    c.execute(make_results)

    insert_main = &quot;&quot;&quot;INSERT INTO main (id, test_ids, train_ids, mean_margin) VALUES (null, ?, ?, ?)&quot;&quot;&quot;
    c.execute(insert_main, main_row)
    conn.commit()

    #get id for row you just inserted
    main_id = c.execute(&quot;&quot;&quot;SELECT id FROM main ORDER BY id DESC&quot;&quot;&quot;).fetchone()[0]
    insert_result = &quot;&quot;&quot;INSERT INTO results (id, main_id, doc_id, predicted, actual, margin) VALUES (null, ?, ?, ?, ?, ?)&quot;&quot;&quot;
    for result_row in result_rows:
        new_row = [main_id]
        new_row.extend(result_row)
        c.execute(insert_result, new_row)
    conn.commit()
&lt;/pre&gt;&lt;h3&gt;Shuffle Up and Deal&lt;/h3&gt;
&lt;p&gt;In many cases, it's best to add second layer of randomness. Instead of simply partitioning your data once and checking your
performance, you can run the model and collect results, then shuffle up the memberships of test and train and re-run. If you go through this
process enough times, you start to get a sense of which random arrangements of the training set might be outliers when compared with all the
other potential arrangements. Since my regression function will shuffle train and test automatically each time it is run, the code to
execute this shuffle and re-run method can be as simple as this:&lt;/p&gt;
&lt;pre&gt;
#for every number, 0 to 299
for z in range(300):
    #re-run the result function
    result_tuple = predict_years(metadata, feature_dicts)
    #re-run the datastore function
    store_results(result_tuple[0], result_tuple[1])
    #this print statement is just here to print a progress report to the terminal every tenth time the functions finish
    if z % 10 == 0:
        print(z)
&lt;/pre&gt;&lt;h3&gt;Normal Distribution?&lt;/h3&gt;
&lt;p&gt;After running the regression 100, 200 or even 600 times (which is easier to cope with since we've improved the overall speed
of the program), we start to get a sense of what most models tend to predict a document's date to be. Using our sqlite database,
we can quickly get all the results for a given Document ID:&lt;/p&gt;
&lt;pre&gt;
&quot;&quot;&quot;SELECT avg(predicted) as a, actual, doc_id FROM results GROUP BY doc_id;&quot;&quot;&quot;
&lt;/pre&gt;&lt;p&gt;This query will give us the mean prediction, a labeled date, and a Document ID from our results table.
From here, we can calculate the margin between each prediction and its corresponding metadata.
If we bundle all of these together predictions and margins together, we can get a sense of their overall
distribution.&lt;/p&gt;
&lt;p&gt;&lt;img src='/static/images/distribution.png' /&gt;&lt;/p&gt;
&lt;p&gt;What we see here is something resembling normal distribution. The peak in the middle is higher than you would expect
of a normal distribution (or more kurtotic in stat-speak), and there are some extreme outliers if you look at either tail.
Since we're grabbing values from our database, the code to generate this plot is as simple as:&lt;/p&gt;
&lt;pre&gt;
import seaborn as sns
conn = sqlite3.connect('regression_scores.db')
c = conn.cursor()
query = &quot;&quot;&quot; SELECT avg(predicted) as m, actual, doc_id FROM results GROUP BY doc_id; &quot;&quot;&quot;
results_two_sided = c.execute(query).fetchall()
results_two_sided_margins = [(i[0] - i[1]) for i in results_two_sided]
pylab.rcParams['figure.figsize'] = (11, 6)
sns.distplot(results_two_sided_margins)
&lt;/pre&gt;&lt;p&gt;We can now compute how far from the mean our outliers are. Anything more than 2.5 standard deviations from the mean should
be immediately suspect. These would be good targets for additional scrutiny. (I've read that the MAD score or &quot;median absolute
distance&quot; is a better way to detect fishy outliers but I'm sticking with standard deviation for the moment out of expediency).&lt;/p&gt;
&lt;h3&gt;Visualizing Date Predictions&lt;/h3&gt;
&lt;p&gt;At Keystone DH, I presented a static scatter plot of predicted dates vs. labeled dates based upon a far less successful date
prediction model (based on neologism ratios instead of term frequencies).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/static/images/lovecraft_machine_learn.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;People were interested in the visualization, but almost everyone I talked to wanted a way to look closer which texts were
outliers. Scatter plots in matplotlib (which is how I made the plot) tend to be all or nothing in terms of labels, so I
started thinking about how I could make an interactive web app to show the same kind of data. Here's what I came up with:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://neo.matthew-lavin.com&quot;&gt;Neologophobia Web Application&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To make this interactive scatter plot, I've hijacked the Mapbox visualization codebase to and replaced the base map with
graph lines. Mapbox.js handles the panning, zooming, and marker clustering. If you click on any cluster, the map will
automatically zoom in and unpack the data data points. Clicking on any data point will open a document popup, and clicking
the link on a popup will bring you to a landing page for that document.&lt;/p&gt;
&lt;h3&gt;Outliers&lt;/h3&gt;
&lt;p&gt;Visually, it's easy to spot totally bizarre results. Any plotted point that's on its own (not clustered with others is a clear
outlier.) Still others can be identified by zooming in one step further. The closer a point is to the red-orange line, the
less distance there is between the predicted date and the labeled date. For example, if you go to the web app and click on
this point ...&lt;/p&gt;
&lt;p&gt;... you will see that the document is Ludwig Geissler's &lt;em&gt;Looking Beyond&lt;/em&gt;. The predicted date is 1893, and the metadata
lists it as a text published in 1971. This is one of the largest margins of error in the entire set. However, if we look up
Ludwig Geissler's &lt;em&gt;Looking Beyond&lt;/em&gt;, we can easily discover that this work was in fact published in 1891.
(See this &lt;a href=&quot;http://www.sf-encyclopedia.com/entry/geissler_ludwig_a&quot;&gt;SF Encyclopedia&lt;/a&gt; entry.) Our model has successfully
located a metadata error.&lt;/p&gt;
&lt;p&gt;Another example is &lt;em&gt;Weird Tidbits&lt;/em&gt;, New York, 1888, with a mean predicted date of 1848. Here the model might just be wrong,
but it's worth noting that it seems to have been advertised as a five-volume collection of pieces &quot;from various sources,&quot; so any
number of these might be older than others (See &quot;Books Wanted,&quot; &lt;em&gt;Publisher's Weekly&lt;/em&gt;, July 22, 1905. 138.). Further inspection is warranted here, of course.&lt;/p&gt;
&lt;p&gt;My favorite example is &lt;em&gt;Madame de Maintenon&lt;/em&gt;, published in 1806, predicted at 1918, but with predictions all over the map
(1998, 1796, etc.) if you look at the results data. Closer inspection of this document reveals that it is in French. The model
assumes English language texts, so it's no wonder that this text is an outlier!&lt;/p&gt;
&lt;h3&gt;Next steps&lt;/h3&gt;
&lt;p&gt;The next step is to cull or relabel erroneous texts, retrain the model, and see how it performs. Once its date prediction
accuracy seems stable, I'll start looking at the next set of outliers, whose status as such should have more literary
or cultural significance.&lt;/p&gt;
</content>
  </entry>
  <entry xml:base="http://matthew-lavin.com/blog/the-alice-problem/">
    <title type="text">The Alice Problem</title>
    <id>urn:uuid:ad784a86-d690-30a9-a1d9-cc8da4fb43eb</id>
    <updated>2016-12-15T00:00:00Z</updated>
    <link href="http://matthew-lavin.com/blog/the-alice-problem/" />
    <author>
      <name>Matt Lavin</name>
    </author>
    <content type="html">&lt;h3&gt;The Conceit&lt;/h3&gt;&lt;p&gt;Not very long ago, one of my colleagues hired a programmer for his institution's digital humanities initiative. In advertising the position, he designed a set of three challenges designed to test candidates for baseline competency with programming as it might apply to the humanities. All three of the tasks were of the same sort and, honestly, I can only remember one of them.&lt;/p&gt;
&lt;p&gt;It asked the candidate programmer to design a simple block of code, in any programming language, to return a list of the most frequent adjectives preceding the name &lt;em&gt;Alice&lt;/em&gt; in the book &lt;em&gt;Alice’s Adventures in Wonderland&lt;/em&gt; (1865).&lt;/p&gt;
&lt;p&gt;Programmer competency tasks are fairly common but, in the constellation of what would-be programmers are asked to do, this one seemed different.&lt;/p&gt;
&lt;p&gt;This task is not remarkable in its difficulty. In general, I tend to get sucked into coding when I'm presented with something challenging. I suspect this is the case for almost anyone who codes regularly. Programming can be very difficult, but it's often difficult in exactly the right way: even partial successes are immediately observable and utterly distinct from an outright failure. In video game studies, gamers motivated like I am are called &quot;achievers.&quot; Making something work, especially it was hard, feels good, much like beating a boss, or earning a badge, or unlocking a secret level.&lt;/p&gt;
&lt;p&gt;&lt;h3&gt;A Solution&lt;/h3&gt;
But I can’t say that the Alice Problem really appeals to my achiever side, because it isn't very hard. A simplified solution might go something like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read the full text of &lt;em&gt;Alice’s Adventures in Wonderland&lt;/em&gt; into memory and store it as a string.&lt;/li&gt;
&lt;li&gt;Go through the text and tokenize such that every word is treated separately from every other word.&lt;/li&gt;
&lt;li&gt;Use one of any number of Part-of-Speech (POS) taggers to generate a best guess for the part of speech for each token.&lt;/li&gt;
&lt;li&gt;Go through the text word by word. If the word is &quot;Alice,&quot; look at the part of speech value to the left (one common approach to this type of question is called Key Words in Context or KWIC).&lt;/li&gt;
&lt;li&gt;If the word to the left is an adjective, store its value. If the word has appeared before, add to a count of the total number of occurrences for that adjective&lt;/li&gt;
&lt;li&gt;Sort the results by the number of occurrences.&lt;/li&gt;
&lt;li&gt;Return or print the result.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;h3&gt;Some Code&lt;/h3&gt;
Using Python, my typical programming language of choice, this task is especially easy to tackle because the pieces needed to accomplish the tasks are all associated with one very popular library, the Natural Language Toolkit (nltk). This script does approximately what my list above describes.&lt;a class=&quot;footnote&quot; href=&quot;#note_1&quot;&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;
import nltk
with open('alice.txt') as a:
    alice_text = a.read()
alice_tokens = nltk.word_tokenize(alice_text.lower())
alice_pos = nltk.pos_tag(alice_tokens)
alice_pos = [i for i in alice_pos if i[0].isalpha()]
adjs = []
for i, j in enumerate(alice_pos):
    if j[0]=='alice':
        before = i-1
        if alice_pos[before][1] == 'JJ':
            adjs.append(alice_pos[before][0])
from collections import Counter
print(Counter(adjs).most_common())
&lt;/pre&gt;
The output, using the Natural Language Toolkit's default Part-of-Speech tagger, is a list of term counts that looks like this:
&lt;pre&gt;
[('thought', 26), ('poor', 11), ('cried', 7), ('little', 3), ('exclaimed', 3), ('shouted', 1), ('red', 1), ('inquired', 1), ('foolish', 1), ('interrupted', 1), ('pleaded', 1), ('replied', 1), ('noticed', 1), ('miss', 1), ('anxious', 1), ('different', 1), ('upon', 1)]
&lt;/pre&gt;&lt;p&gt;&lt;h3&gt;Some Immediate Caveats&lt;/h3&gt;
Before anything else, I should acknowledge issues with the accuracy of this tagger. It has incorrectly labelled &quot;thought,&quot; &quot;cried,&quot; and multiple other verbs as adjectives. We might hypothesize that adjectives such as &quot;poor&quot; and &quot;little&quot; will remain our top results with these mislabeled verbs excluded, but a parser with this
many false positives could be missing any number of adjectives. On the other hand, these verbs are all like to be associated with dialogue attribution (as in &quot;cried Alice&quot; and &quot;thought Alice&quot;), so the errors could be concentrated around this particular sentence structure.&lt;/p&gt;
&lt;p&gt;I also want to signal my awareness of numerous general ways to improve the code overall. An employer hiring an imaginary programmer for a digital humanities initiative might be specifically interested in whether the candidates used object-oriented programming,
particular libraries, and any number of stylistic approaches.&lt;/p&gt;
&lt;p&gt;These caveats aside, the necessary steps I've outlined would be quite familiar to any programmer computationally-inclined digital humanist, so
I can see why a task like this might serve as a reasonable as a measure of a programmer's ability to write code that engages with a humanities computing problem.&lt;/p&gt;
&lt;p&gt;&lt;h3&gt;Simplicity is Complicated&lt;/h3&gt;
The problem is simple. The problem is deceptively complicated. Welcome to humanities computing.&lt;/p&gt;
&lt;p&gt;One solution or another is easy to code, but the underlying question is complex, especially if one chooses to emphasize how this problem relates to reading &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt;.
There is a question beneath this problem that has little to do with adjectives directly to the left of the name &lt;em&gt;Alice&lt;/em&gt;. Rather, adjectives and adjacency are boundaries for the applicant to work with while sketching a computational perimeter
around a more nuanced question:&lt;/p&gt;
&lt;blockquote&gt;
&quot;How does Carroll describe Alice, and what are the implications of this description?&quot;
&lt;/blockquote&gt;
Or, perhaps more ambitiously:
&lt;blockquote&gt;
&quot;How does Carroll's description of Alice compare with other characters in other texts?&quot;&lt;/blockquote&gt;
Or, perhaps going even further:
&lt;blockquote&gt;
&quot;How does descriptive language in &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt; compare broadly to other narratives with imagined landscapes?
And how might descriptive patterns help a reader situate &lt;em&gt;Alice&lt;/em&gt; in relation to its historical and formal context?&quot;
&lt;/blockquote&gt;&lt;p&gt;These questions should have implications for the various humanities scholarship that has considered &lt;em&gt;Alice&lt;/em&gt;'s place in the history of children's literature.
For example, Beatrice Turner's &quot;'Which is to be master?': Language as Power in &lt;em&gt;Alice in Wonderland&lt;/em&gt; and &lt;em&gt;Through the Looking-Glass&lt;/em&gt;&quot;
argues that &quot;most of [Alice's] exchanges with the inhabitants of Wonderland and the Looking-glass world&quot; are marked
by a &quot;power imbalance ... that is worked out at the level of language&quot; (246).&lt;a class=&quot;footnote&quot; href=&quot;#note_2&quot;&gt;2&lt;/a&gt; I am not immediately persuaded by Turner's argument,
but it represents for me a productive site of engagement with the text because it invites additional interpretation.&lt;/p&gt;
&lt;p&gt;Most immediately, Turner's work reminds me that questions about descriptive norms in &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt; and other children's fiction are affected by
the way people (men, women, children, adults) interact, and those interactions legitimize or undermine a person's right to observe, react, and speak.&lt;/p&gt;
&lt;p&gt;I think Turner's sharpest point is that Alice is a little girl, and the characters around her, despite being erratic and nonsensical and even infuriating at times, are basically cast as adults.&lt;/p&gt;
&lt;p&gt;&quot;The texts grant linguistic control to those who inhabit Wonderland and the Looking-glass world,&quot; she argues, &quot;and, in doing so, define them as adults. They use this
control in a very adult way, too: they exercise the adult’s right to tell the child what she is&quot; (249). Looking at adjectives to the immediate left of the name &lt;em&gt;Alice&lt;/em&gt; is merely one
immediate and quantifiable way to gesture at broader issues like this one. The fact that &lt;em&gt;Alice&lt;/em&gt; is described as little, poor, foolish, anxious, and different begins to substantiate
Turner's initial observation about how Carroll frames Alice.&lt;/p&gt;
&lt;p&gt;&lt;h3&gt;&quot;Through the Looking Glass&quot; as a Strained Metaphor for Something Far Less Interesting than Interdimensional Travel&lt;/h3&gt;
One issue with &quot;adjectives to the left of Alice&quot; is that it's a relatively narrow way to think about how Alice is described. To begin to address the broader question,&lt;/p&gt;
&lt;p&gt;&lt;blockquote&gt;
&quot;How does Carroll describe Alice, and what are the implications of this description?&quot;
&lt;/blockquote&gt;
I would prefer a computational method with more interpretive reach. Instead of designing a tool to look specifically for adjectives next to Alice,
for example, we could design an instrument to ask what kinds of term pairs tend to co-occur more generally in the novel. To set up this test, I could use the NLTK's collocations function.&lt;/p&gt;
&lt;pre&gt;
from nltk.collocations import *
bigram_measures = nltk.collocations.BigramAssocMeasures()
at = [i for i in alice_tokens if i.isalpha()]
finder = BigramCollocationFinder.from_words(at)
finder.apply_freq_filter(3)
ignored_words = nltk.corpus.stopwords.words('english')
finder.apply_word_filter(lambda w: len(w) &lt; 3 or w.lower() in ignored_words)
terms = []
for i in finder.nbest(bigram_measures.pmi, 10000):
    if &quot;alice&quot; in i:
        print(i)
&lt;/pre&gt;&lt;p&gt;This code uses a function called &quot;collocations&quot; to look for common bigrams in &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt;. By bigrams, I mean pairs of adjacent words.
For the purposes of this measure, I've removed all punctuation from the text and made all words lowercase so that &quot;afraid&quot; and &quot;Afraid&quot;, for example, would read as the same term.
I've set the code to ignore any term that doesn't appear at least three times, and I've removed from consideration any pairs that use excessively common &quot;function words&quot; like &lt;em&gt;the&lt;/em&gt;, &lt;em&gt;as&lt;/em&gt;, and &lt;em&gt;in&lt;/em&gt;.
(For a full list of these stopwords, see this &lt;a href=&quot;https://gist.github.com/sebleier/554280&quot;&gt;Github Gist&lt;/a&gt;.)
The above code snippet will only output term pairs of one of the terms is &quot;Alice.&quot; The result of collocated terms does not focus on any particular part-of-speech, but several adjectives are easy to pick out.&lt;/p&gt;
&lt;pre&gt;
('alice', 'ventured')
('alice', 'indignantly')
('exclaimed', 'alice')
('poor', 'alice')
('thought', 'alice')
('cried', 'alice')
('together', 'alice')
('alice', 'replied')
('alice', 'waited')
('said', 'alice')
('alice', 'hastily')
('alice', 'felt')
('alice', 'looked')
('alice', 'asked')
('alice', 'thought')
('alice', 'could')
('alice', 'began')
('alice', 'rather')
('caterpillar', 'alice')
('alice', 'heard')
('alice', 'quite')
('alice', 'must')
('alice', 'went')
('alice', 'said')
('little', 'alice')
&lt;/pre&gt;&lt;p&gt;In the context of this collocations analysis, the only two adjectives that rank among the top associations with &quot;Alice&quot; are &quot;poor&quot; and &quot;little.&quot;
One renders the protagonist (albeit ironically) as an object of pity, and the other reinforces her status as a child and a figure of reduced physical and social stature.&lt;/p&gt;&lt;p&gt;Perhaps more striking is the fact that so many of these collocations situate Alice in dialogue. Terms like &quot;asked&quot;, &quot;began&quot;, &quot;said&quot;, &quot;exclaimed&quot;, and &quot;ventured&quot; are specific dialogue tags (i.e., verbs).
Terms like &quot;thought&quot;, &quot;look&quot;, &quot;felt&quot;, &quot;heard&quot;, and &quot;indignantly&quot; indirectly situate her in dialogue as well. These terms convey an Alice who is often listening, reacting internally, or conveying confusion or frustration without
necessarily taking specific actions to resist.&lt;/p&gt;&lt;p&gt;&lt;h3&gt;A Continuously Widening Spiral of Comparison&lt;/h3&gt;&lt;/p&gt;
&lt;p&gt;Still, we might ask whether these word associations are the symptoms of a character constrained by her age and gender, or simply the kinds of words that any main character is
likely to be associated with in a children's novel of this time period. After all, the rise of dialogue in 19th-century fiction could easily account for at least some of these associations.&lt;/p&gt;&lt;p&gt;One way to address these concerns is to compare &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt; to other texts (or authors, or genres, etc.).
Take, for example, a a quick analysis of just a few female protagonists from novels about girls who visit other worlds. How do descriptions of these female main characters differ from how Alice is described?&lt;/p&gt;&lt;p&gt;A question like this is one that Turner (and many others), using situationally specific methods, cannot answer. Queries with large-scale scope are notoriously difficult to approach without computation.&lt;/p&gt;&lt;p&gt;An extensive search for novels about girls who visit other worlds would no doubt reveal any examples, but a few very well known archetypes come to mind: Dorothy in
&lt;em&gt;The Wonderful Wizard of Oz&lt;/em&gt; (1900), Wendy in &lt;em&gt;Peter and Wendy&lt;/em&gt; (1910), and Lucy and Susan in &lt;em&gt;The Lion, the Witch, and the Wardrobe&lt;/em&gt; (1950).&lt;/p&gt;&lt;p&gt;If we replicate the two computations I performed on &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt; using these three texts, we can begin to form a basis for comparison.&lt;/p&gt;&lt;p&gt;It's important to note that these are all male authors. Here I am not asking a question like, &quot;Did women authors of the 19th and 20th centuries write female characters with more signs of individual agency than men,&quot; although I think a question like this one would be fascinating to explore. Instead, I'm merely
investigating which terms are most often adjacent to five characters names in four very well known novels about girls who visit fantasy realms.&lt;/p&gt;&lt;pre&gt;
import nltk
import nltk.collocations
def collocation_analysis(text, character):
    with open(text) as a:
        my_text = a.read()
    my_tokens = nltk.word_tokenize(my_text.lower())
    bigram_measures = nltk.collocations.BigramAssocMeasures()
    at = [i for i in my_tokens if i.isalpha()]
    finder = BigramCollocationFinder.from_words(at)
    finder.apply_freq_filter(3)
    ignored_words = nltk.corpus.stopwords.words('english')
    finder.apply_word_filter(lambda w: len(w) &lt; 3 or w.lower() in ignored_words)
    terms = []
    pairs = []
    for i in finder.nbest(bigram_measures.pmi, 10000):
        if character in i:
            pairs.append(i)
    return pairs

output = []
for i, j in comparison_texts:
    pairs = collocation_analysis(i, j)
    output.append(pairs)
&lt;/pre&gt;&lt;p&gt;Granted, these texts are separate by many years, and Lucy and Susan might be prone to appearing as outliers because they are two of four main characters in &lt;em&gt;The Lion, the Witch, and the Wardrobe&lt;/em&gt;.
Still, I think the commonalities among these books are more important than the differences.&lt;/p&gt;
&lt;p&gt;The above code will output a list of term pairs for each text just like the one for Alice shown above. However, this output doesn't necessarily help us compare the various characters.
In the following table, I've made a row for each term and a column for each character. An X in a cell means that a given term and a given character can be considered a computed association:&lt;/p&gt;&lt;table class=&quot;table table-bordered table-hover table-condensed&quot;&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th title=&quot;Field #1&quot; &gt;&lt;/th&gt;
&lt;th title=&quot;Field #2&quot;&gt;term&lt;/th&gt;
&lt;th title=&quot;Field #3&quot;&gt;lucy&lt;/th&gt;
&lt;th title=&quot;Field #4&quot;&gt;susan&lt;/th&gt;
&lt;th title=&quot;Field #5&quot;&gt;dorothy&lt;/th&gt;
&lt;th title=&quot;Field #6&quot;&gt;wendy&lt;/th&gt;
&lt;th title=&quot;Field #7&quot;&gt;alice&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;0&lt;/td&gt;
&lt;td&gt;saw&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;1&lt;/td&gt;
&lt;td&gt;picked&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;2&lt;/td&gt;
&lt;td&gt;story&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;3&lt;/td&gt;
&lt;td&gt;queen&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;4&lt;/td&gt;
&lt;td&gt;exclaimed&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;5&lt;/td&gt;
&lt;td&gt;went&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;6&lt;/td&gt;
&lt;td&gt;little&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;7&lt;/td&gt;
&lt;td&gt;returned&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;8&lt;/td&gt;
&lt;td&gt;asked&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;9&lt;/td&gt;
&lt;td&gt;could&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;10&lt;/td&gt;
&lt;td&gt;presently&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;11&lt;/td&gt;
&lt;td&gt;together&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;12&lt;/td&gt;
&lt;td&gt;heard&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;13&lt;/td&gt;
&lt;td&gt;thought&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;14&lt;/td&gt;
&lt;td&gt;answered&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;15&lt;/td&gt;
&lt;td&gt;began&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;16&lt;/td&gt;
&lt;td&gt;lady&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;17&lt;/td&gt;
&lt;td&gt;walked&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;18&lt;/td&gt;
&lt;td&gt;waited&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;19&lt;/td&gt;
&lt;td&gt;wendy&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;20&lt;/td&gt;
&lt;td&gt;whispered&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;21&lt;/td&gt;
&lt;td&gt;put&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;22&lt;/td&gt;
&lt;td&gt;hastily&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;23&lt;/td&gt;
&lt;td&gt;mother&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;24&lt;/td&gt;
&lt;td&gt;said&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;25&lt;/td&gt;
&lt;td&gt;poor&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;26&lt;/td&gt;
&lt;td&gt;peter&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;27&lt;/td&gt;
&lt;td&gt;last&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;28&lt;/td&gt;
&lt;td&gt;ventured&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;29&lt;/td&gt;
&lt;td&gt;sat&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;30&lt;/td&gt;
&lt;td&gt;felt&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;31&lt;/td&gt;
&lt;td&gt;replied&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;32&lt;/td&gt;
&lt;td&gt;must&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;33&lt;/td&gt;
&lt;td&gt;indignantly&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;34&lt;/td&gt;
&lt;td&gt;caterpillar&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;35&lt;/td&gt;
&lt;td&gt;suddenly&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;36&lt;/td&gt;
&lt;td&gt;came&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;37&lt;/td&gt;
&lt;td&gt;looked&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;38&lt;/td&gt;
&lt;td&gt;would&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;39&lt;/td&gt;
&lt;td&gt;rather&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;40&lt;/td&gt;
&lt;td&gt;quite&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;41&lt;/td&gt;
&lt;td&gt;stood&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;42&lt;/td&gt;
&lt;td&gt;see&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;43&lt;/td&gt;
&lt;td&gt;cried&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;44&lt;/td&gt;
&lt;td&gt;well&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;45&lt;/td&gt;
&lt;td&gt;moment&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;46&lt;/td&gt;
&lt;td&gt;says&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;47&lt;/td&gt;
&lt;td&gt;knew&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;right&quot;&gt;48&lt;/td&gt;
&lt;td&gt;found&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;XXXXX&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;td&gt;-----&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Based on this table, we can notice some immediately fascinating aspects of the comparison. It makes it much easier to find terms associated with only one or two characters, as well as associations present for all &lt;em&gt;but&lt;/em&gt; one or two characters. For example:&lt;/p&gt;&lt;p&gt;Lucy: uniquely associated with last and suddenly. No unique absences.&lt;/p&gt;
&lt;p&gt;Susan: uniquely associated with presently, whispered, and Peter. Uniquely not associated with cried and could.&lt;/p&gt;
&lt;p&gt;Wendy: uniquely associated with story, lady, mother, see, says, and knew. Uniquely not associated with absent and asked
&lt;p&gt;Dorothy: uniquely associated with returned, answered, walked, and put. No unique absences.&lt;/p&gt;
&lt;p&gt;Susan and Wendy: neither associated with thought or looked&lt;/p&gt;
&lt;p&gt;Alice and Dorothy; associated with replied, exclaimed, went&lt;/p&gt;
&lt;p&gt;Dorothy and Wendy: associated with saw, would&lt;/p&gt;
&lt;p&gt;Lucy and Wendy: associated with moment&lt;/p&gt;
&lt;p&gt;Alice: uniquely associated with little, poor, together, heard, began, waited, hastily, ventured, must, indignantly, caterpillar, rather, quite&lt;/p&gt;&lt;p&gt;These findings warrant more discussion than I'm planning on doing here today. For now, a few highlights. First, this comparative approach only strengthens the association between Alice, little, and poor established by a part-of-speech tagging approach.
Further, the pairing of waited and hastily, typically oppositional terms, reminds of a character constantly trying to move along but getting held up by others. Similarly, the term &lt;em&gt;began&lt;/em&gt;, likewise, conjures images of a character attempting to speak but getting consistently interrupted.
Adding to the sense of both situational and verbal irony are the terms &lt;em&gt;rather&lt;/em&gt; and &lt;em&gt;quite&lt;/em&gt;, both of which seem likely to be tongue-in-cheek qualifiers (e.g. &quot;Alice quite jumped&quot;). &lt;/p&gt;&lt;p&gt;In this example, we knew the main characters' names, so the comparison is a bit easier. Scaling this question beyond our example would requiring making a dictionary of main character names or developing a method that detected character names automatically.
This is just one example of a continuously widening spiral of comparison. Additional layers are always possible, which is one of the main reasons it's so appealing to sit and tinker.&lt;/p&gt;&lt;p&gt;In the past, I have described digital humanities using the metaphor of an investigator who uses advances tools and approaches look through a keyhole, only to find that, inside the locked room there is only a mirror.
This is to say that digital humanities methods, too often, become lenses through which the only result is a more nuanced understanding of digital humanities. I am confident that meditating on
the advantages and limits of our methods has purchase, yet, here I believe light is also shed on &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;p&gt;I must concede, of course, that it is possible that these alternative close reading strategies mostly confirm what others have noticed using more traditional literary analysis methods.
If this is so, then code is still a way to get to where we want to go, a way to establish the habits of mind that lovers of close reading are always trying to instill in their students and colleagues.
The real challenge is taking the time to share one's results with others. This is inevitably a decision to stop, which eventually requires stopping. And so I have chosen to conclude with a partial list of how much more I want to do.&lt;/p&gt;
&lt;p&gt;&lt;h3&gt;Ideas for Follow-up&lt;/h3&gt;&lt;/p&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;Compare adjectives overall to lots of novels&lt;/div&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;On many novels: return the names after &quot;little&quot; (and other adjectives) ranked by how often those names are referred to as little. Are those names gendered?&lt;/div&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;Explore character-based sentiment tagging, in response to (if possible) Michael Mendelson's &quot;The phenomenology of deep surprise in &lt;em&gt;Alice's Adventures in Wonderland&lt;/em&gt;&quot;&lt;/div&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;Use SpaCy or Parsey McParseface or for better POS tagging&lt;/div&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;Explore how to perform similar analysis on novels without knowing main characters' names&lt;/div&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;Attempt to run using pronoun disambiguation&lt;/div&gt;
&lt;div class=&quot;follow-up-entry&quot;&gt;Re-run multi-novel analysis using collocations two and three words away from characters' names&lt;/div&gt;&lt;p&gt;&lt;h3&gt;Notes&lt;/h3&gt;&lt;/p&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_1&quot;&gt;1. Code excerpts can be viewed in or downloaded/run from the .ipynb file in &lt;a href=&quot;https://github.com/mjlavin80/the-data-humanist-jupyter-notebooks/tree/master/alice&quot;&gt;this folder&lt;/a&gt; in my Jupyter Notebooks Github repository&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_2&quot;&gt;2. Turner, Beatrice. &quot;'Which is to be master?': Language as Power in &lt;em&gt;Alice in Wonderland&lt;/em&gt; and &lt;em&gt;Through the Looking-Glass&lt;/em&gt;,&quot;
 &lt;em&gt;Children's Literature Association Quarterly&lt;/em&gt;, 35.3 (Fall 2010): 243-254.
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://matthew-lavin.com/blog/about/">
    <title type="text">About this Blog-like Thing</title>
    <id>urn:uuid:62583394-e8e7-31f2-b90f-062dfaaae20f</id>
    <updated>2016-09-01T00:00:00Z</updated>
    <link href="http://matthew-lavin.com/blog/about/" />
    <author>
      <name>Matt Lavin</name>
    </author>
    <content type="html">&lt;p&gt;Since the late 1990s, the business world and academia alike have seen the rise of the data scientist.
Though the term &lt;em&gt;data science&lt;/em&gt; dates back to early 1960s, figure of the data scientist took on additional cache with the popularization of the World Wide Web and the data revolution that accompanied it.
&lt;a class=&quot;footnote&quot; href=&quot;#note_1&quot;&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;These conceptualized experts were said to be
&quot;the information and computer scientists, database and software engineers and programmers,
disciplinary experts, curators and expert annotators, librarians, archivists,
and others, who are crucial to the successful management of a digital data collection.&quot;&lt;a class=&quot;footnote&quot; href=&quot;#note_2&quot;&gt;2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In 2012, &lt;em&gt;Harvard Business Review&lt;/em&gt; named data scientist the &quot;sexiest job of the 21st century.&quot;&lt;a class=&quot;footnote&quot; href=&quot;#note_3&quot;&gt;3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The data humanist, in contrast, has not arisen as a figure. Instead of &lt;em&gt;data humanities&lt;/em&gt;, we have seen the rise of &lt;em&gt;digital humanities&lt;/em&gt; as a catch-all term for humanities computing, digital librarianship, digital project development, digital pedagogy, and humanities-based data curation.&lt;/p&gt;
&lt;p&gt;Data remains the backstop of much if not all digital humanities work, either directly (in the case of, say, Matt Jockers' work on sentiment analysis) or indirectly (as in, say, the numerous critiques of Jockers' work on sentiment analysis).&lt;/p&gt;
&lt;p&gt;This particular topic is of interest me because I work in a space where digital humanities and digital media intersect. I'm a Clinical Assistant Professor of English and Director of the Digital Media Lab at the University of Pittsburgh. My most recent scholarship focuses on the intersection of digital humanities, book history, and U.S. literature. My programming languages of choice are Python and javascript, will a little R peppered in. My web stack includes, Ubuntu, Docker, Nginx, WSGI, and Python.
I use Lektor and Flask for websites, and I like Jupyter Notebooks.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://github.com/mjlavin80&quot;&gt;This&lt;/a&gt; is me, and &lt;a href=&quot;http://twitter.com/mjlavin80&quot;&gt;this&lt;/a&gt; is me, and &lt;a href=&quot;http://www.english.pitt.edu/person/matthew-j-lavin&quot;&gt;this&lt;/a&gt; is me,
and &lt;a href=&quot;http://matthew-lavin.com&quot;&gt;this&lt;/a&gt; is me.&lt;/p&gt;
&lt;p&gt;I should probably mention that the Data Humanist won't be a very good blog, because it's barely a blog at all. Most blogs (even really good digital humanities blogs) feel a certain amount of pressure to post regularly and, to accommodate that pressure, they sometimes feel the need to slap together very short or shoddy or off-topic filler to give the appearance of an active blog.
I don't mean to be overly critical of this impulse; I'm just saying it's stupid and I hate it. :)&lt;/p&gt;
&lt;p&gt;So I will aspire to do less posting but to release posts will a bit more heft. Hence the phrase &quot;blog-like thing.&quot;&lt;/p&gt;
&lt;p&gt;Content will begin in &lt;span style=&quot;text-decoration: line-through;&quot;&gt;October&lt;/span&gt; &lt;em&gt;[edit: well, that didn't happen. Here it is mid-December, and I'm about to publish my first post.]&lt;/em&gt; and follow approximately once per month. I plan to do this for 12 months, and then reevaluate my approach.&lt;/p&gt;
&lt;p&gt;I hope this blog-like thing will be a space where &lt;em&gt;data&lt;/em&gt; isn't a dirty word. I plan to write about scraping, wrangling, curating, analyzing, visualizing, teaching, and critique--the entire lifecycle of humanities data. I plan to integrate multi-modal content and dissect it. I plan to share Jupyter Notebooks via Github so people can see my code.&lt;/p&gt;
&lt;p&gt;&lt;h3&gt;Notes&lt;/h3&gt;&lt;/p&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_1&quot;&gt;1. Press, Gil. &lt;a href=&quot;http://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/&quot;&gt;
&quot;A Very Short History of Data Science,&quot;&lt;/a&gt; &lt;em&gt;Forbes&lt;/em&gt; (May 28, 2013).
&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_2&quot;&gt;2. &lt;a href=&quot;http://www.nsf.gov/pubs/2005/nsb0540/&quot;&gt;&quot;Long-Lived Digital Data Collections: Enabling Research and Education in the 21st Century,&quot;&lt;/a&gt;
September 2005, National Science Foundation, NSB-05-40.
&lt;/div&gt;
&lt;div class=&quot;note_entry&quot; name=&quot;note_3&quot;&gt;3. Davenport, Thomas H., and D.J. Patil. &lt;a href=&quot;https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century&quot;&gt;&quot;Data Scientist: The Sexiest Job of the 21st Century,&quot;&lt;/a&gt; &lt;em&gt;Harvard Business Review&lt;/em&gt; (October 2012).
&lt;/div&gt;</content>
  </entry>
</feed>
