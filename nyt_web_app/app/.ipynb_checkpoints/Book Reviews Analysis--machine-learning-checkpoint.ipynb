{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load ocr_counters_all, fullstops from pickles\n",
    "import pickle\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'rb') as handle:\n",
    "    ocr_counters_all = pickle.load(handle)\n",
    "with open('pickled_data/fullstops.pickle', 'rb') as handle2:\n",
    "    fullstops = pickle.load(handle2)\n",
    "with open('pickled_data/nyt_ids_all.pickle', 'rb') as handle3:\n",
    "    nyt_ids_all = pickle.load(handle3)\n",
    "with open('pickled_data/fullstops_and_pronouns.pickle', 'rb') as handle4:\n",
    "    fullstops_and_pronouns = pickle.load(handle4)\n",
    "with open('pickled_data/fullstops_pronouns_and_names.pickle', 'rb') as handle5:\n",
    "    fullstops_pronouns_and_names = pickle.load(handle5)\n",
    "with open('pickled_data/nrc_positive.pickle', 'rb') as handle6:\n",
    "    nrc_positive = pickle.load(handle6)\n",
    "with open('pickled_data/nrc_negative.pickle', 'rb') as handle7:\n",
    "    nrc_negative = pickle.load(handle7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from application.selective_features import dictionaries_without_features, dictionaries_of_features\n",
    "import pandas as pd\n",
    "\n",
    "ocr_counters_no_stops = dictionaries_without_features(ocr_counters_all, fullstops)\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'rb') as handle:\n",
    "    ocr_counters_all = pickle.load(handle)\n",
    "    \n",
    "ocr_counters_no_stops_or_pro = dictionaries_without_features(ocr_counters_all, fullstops_and_pronouns)\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'rb') as handle:\n",
    "    ocr_counters_all = pickle.load(handle)\n",
    "\n",
    "ocr_counters_no_stops_pro_names = dictionaries_without_features(ocr_counters_all, fullstops_pronouns_and_names)\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'rb') as handle:\n",
    "    ocr_counters_all = pickle.load(handle)\n",
    "    \n",
    "nrc_both = nrc_positive + nrc_negative\n",
    "\n",
    "#remove stops, pronouns, proper, etc\n",
    "ocr_counters_positive = dictionaries_of_features(ocr_counters_all, nrc_positive)\n",
    "ocr_counters_positive = dictionaries_without_features(ocr_counters_positive, fullstops_pronouns_and_names)\n",
    "ocr_counters_negative = dictionaries_of_features(ocr_counters_all, nrc_negative)\n",
    "ocr_counters_negative = dictionaries_without_features(ocr_counters_negative, fullstops_pronouns_and_names)\n",
    "ocr_counters_sentiment = dictionaries_of_features(ocr_counters_all, nrc_both)\n",
    "ocr_counters_sentiment = dictionaries_without_features(ocr_counters_sentiment , fullstops_pronouns_and_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_counters_all == ocr_counters_no_stops_pro_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x11eaa9dc0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('regression_scores.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "create_main = \"\"\"CREATE TABLE IF NOT EXISTS main (id INTEGER PRIMARY KEY, features_used TEXT, words_removed TEXT, \n",
    "f1_score_f REAL, precision_f REAL, recall_f REAL, f1_score_m REAL, precision_m REAL, recall_m REAL, accuracy REAL,\n",
    "male_match INTEGER, male_mismatch INTEGER, female_match INTEGER, female_mismatch INTEGER, train_size INTEGER, \n",
    "test_size INTEGER, random_seed INTEGER, test_ids TEXT, train_ids TEXT)\"\"\"\n",
    "\n",
    "create_results = \"\"\"CREATE TABLE IF NOT EXISTS results (id INTEGER PRIMARY KEY, main_id INTEGER, nyt_id TEXT, \n",
    "predicted_gender INTEGER, labeled_gender INTEGER, probability_male REAL, probability_female REAL, FOREIGN KEY(main_id) \n",
    "REFERENCES main(id))\"\"\"\n",
    "\n",
    "create_coef = \"\"\"CREATE TABLE IF NOT EXISTS coefficients (id INTEGER PRIMARY KEY, main_id INTEGER, feature TEXT, \n",
    "score REAL, odds REAL, FOREIGN KEY(main_id) REFERENCES main(id))\"\"\"\n",
    "\n",
    "# CREATE INDICES\n",
    "coef_index = \"\"\"CREATE INDEX IF NOT EXISTS coef_index ON coefficients (id,main_id,feature,score,odds)\"\"\"\n",
    "result_index = \"\"\"CREATE INDEX IF NOT EXISTS result_index ON results (id,main_id,nyt_id,predicted_gender,\n",
    "labeled_gender,probability_male, probability_female)\"\"\"\n",
    "\n",
    "c.execute(create_main)\n",
    "c.execute(create_results)\n",
    "c.execute(create_coef)\n",
    "c.execute(coef_index)\n",
    "c.execute(result_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# begin function\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "def vectorize_and_predict(list_of_counters, parameters):\n",
    "    \n",
    "    v = DictVectorizer()\n",
    "    X = v.fit_transform(list_of_counters)\n",
    "    y = TfidfTransformer()\n",
    "    Z = y.fit_transform(X)\n",
    "    scaled_vsm = Z.toarray()\n",
    "    y_as_list = list(range(len(scaled_vsm)))\n",
    "\n",
    "    for i in range(1000):\n",
    "        #(703, 159)\n",
    "        train_size_int = 662\n",
    "        test_size_int = 200\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_vsm, y_as_list, train_size=train_size_int, \\\n",
    "                                                            test_size=test_size_int, random_state=i)\n",
    "        train_labels = []\n",
    "        # 0 = male here\n",
    "        for pos in y_train:\n",
    "            if pos < 703:\n",
    "                value = 0\n",
    "            else:\n",
    "                value = 1\n",
    "            train_labels.append(value)\n",
    "        test_labels = []\n",
    "        test_nyt_ids = []\n",
    "        for pos in y_test:\n",
    "            test_nyt_ids.append(nyt_ids_all[pos])\n",
    "            if pos < 703:\n",
    "                value = 0\n",
    "            else:\n",
    "                value = 1\n",
    "            test_labels.append(value)\n",
    "        \n",
    "        #spend more time optimizing?\n",
    "        #cw = 703*1.0/(703+159)\n",
    "        cw = 700.0/(700+140)\n",
    "        \n",
    "        # Create classifiers\n",
    "        lr = LogisticRegression(class_weight={0:1-cw, 1:cw})\n",
    "        lr.fit(X_train, train_labels)\n",
    "        results = lr.predict(X_test)\n",
    "        probs = lr.predict_proba(X_test)\n",
    "\n",
    "        #score = lr.score(X_test, test_labels)\n",
    "        \n",
    "        \n",
    "        f_score_f = f1_score(test_labels, results, pos_label=1, average='binary')  \n",
    "        prec_f = precision_score(test_labels, results, pos_label=1, average='binary')\n",
    "        rec_f = recall_score(test_labels, results, pos_label=1, average='binary')\n",
    "        \n",
    "        f_score_m = f1_score(test_labels, results, pos_label=0, average='binary')  \n",
    "        prec_m = precision_score(test_labels, results, pos_label=0, average='binary')\n",
    "        rec_m = recall_score(test_labels, results, pos_label=0, average='binary')\n",
    "        \n",
    "        acc = accuracy_score(test_labels, results)\n",
    "        \n",
    "        y_train = [str(u) for u in y_train]\n",
    "        y_test = [str(z) for z in y_test]\n",
    "\n",
    "        a = ', '.join(y_train)\n",
    "        b = \", \".join(y_test)\n",
    "\n",
    "        cnf_matrix = confusion_matrix(test_labels, results)\n",
    "\n",
    "        #row = [i, a, b, score, train_size_int, test_size_int, ]\n",
    "        row = [parameters['features_used'], parameters['stopwords'], f_score_f, prec_f, rec_f, f_score_m, prec_m, \\\n",
    "               rec_m, acc, cnf_matrix[0][0], cnf_matrix[0][1], cnf_matrix[1][1], cnf_matrix[1][0], train_size_int, \\\n",
    "               test_size_int, i, a, b]\n",
    "        cols= [\"features_used\", \"words_removed\", \"f1_score_f\", \"precision_f\", \"recall_f\", \"f1_score_m\", \"precision_m\", \\\n",
    "               \"recall_m\", \"accuracy\",\"male_match\", \"male_mismatch\", \"female_match\", \"female_mismatch\", \"train_size\", \\\n",
    "               \"test_size\", \"random_seed\", \"train_ids\", \"test_ids\"]\n",
    "        df_main = pd.DataFrame.from_records([row,], columns=cols)\n",
    "        \n",
    "        df_main.to_sql('main', conn, 'sqlite', if_exists='append', index=False)\n",
    "\n",
    "        words = v.vocabulary_.keys()\n",
    "        labeled_coefs = {}\n",
    "        for z in words:\n",
    "            try:\n",
    "                labeled_coefs[z] = lr.coef_[0][v.vocabulary_[z]]\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "        #define main_id\n",
    "        main_id = c.execute(\"SELECT MAX(id) FROM main\").fetchone()[0]\n",
    "        \n",
    "        results_rows = []\n",
    "        #main_id, nyt_id, predicted_gender, labeled_gender\n",
    "        for j, k in enumerate(results):\n",
    "            results_row = (main_id, test_nyt_ids[j], k, test_labels[j], probs[j][0], probs[j][1])\n",
    "            results_rows.append(results_row)\n",
    "        \n",
    "        result_cols = [\"main_id\", \"nyt_id\", \"predicted_gender\", \"labeled_gender\", \"probability_male\", \"probability_female\"]\n",
    "        df_results = pd.DataFrame.from_records(results_rows, columns = result_cols)\n",
    "        df_results.to_sql('results', conn, 'sqlite', if_exists='append', index=False, chunksize=100)\n",
    "                                               \n",
    "        df_coef = pd.DataFrame.from_records(labeled_coefs.items(), columns =[\"feature\", \"score\"])\n",
    "        df_coef['main_id'] = main_id\n",
    "        df_coef['odds'] = np.exp(df_coef['score'])\n",
    "        \n",
    "        #only do the first 2500 rows\n",
    "        df_coef = df_coef.sort_values(by=\"score\", ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        df_coef_f = df_coef.iloc[0:1000]\n",
    "        \n",
    "        df_coef_m = df_coef.iloc[-1001:-1]\n",
    "        df_coef = pd.concat([df_coef_f,  df_coef_m]).reset_index(drop=True)\n",
    "        df_coef_.to_sql('coefficients', conn, 'sqlite', if_exists='append', index=False, chunksize=100) \n",
    "    print(\"finished %s, %s\") % (parameters['features_used'], parameters['stopwords'])\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# end function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished tfidf_full_text_lemmas, nothing_removed\n",
      "finished tfidf_full_text_lemmas, stopwords_only\n",
      "finished tfidf_full_text_lemmas, stopwords_and_pronouns\n",
      "finished tfidf_full_text_lemmas, stopwords_pronouns_and_names\n",
      "finished positive_sentiment, none\n",
      "finished negative_sentiment, none\n",
      "finished sentiment_all, none\n"
     ]
    }
   ],
   "source": [
    "#nothing removed\n",
    "vectorize_and_predict(ocr_counters_all, parameters={'features_used':'tfidf_full_text_lemmas', 'stopwords':'nothing_removed'})\n",
    "\n",
    "#stopwords only removed\n",
    "vectorize_and_predict(ocr_counters_no_stops, parameters={'features_used':'tfidf_full_text_lemmas', 'stopwords':'stopwords_only'})\n",
    "\n",
    "#stopwords and pronouns removed\n",
    "vectorize_and_predict(ocr_counters_no_stops_or_pro, parameters={'features_used':'tfidf_full_text_lemmas', 'stopwords':'stopwords_and_pronouns'})\n",
    "\n",
    "#stopwords and pronouns and proper names removed\n",
    "vectorize_and_predict(ocr_counters_no_stops_pro_names, parameters={'features_used':'tfidf_full_text_lemmas', 'stopwords':'stopwords_pronouns_and_names'})\n",
    "\n",
    "#positive terms\n",
    "vectorize_and_predict(ocr_counters_positive, parameters={'features_used':'positive_sentiment', 'stopwords':'none'})\n",
    "\n",
    "#negative\n",
    "vectorize_and_predict(ocr_counters_negative, parameters={'features_used':'negative_sentiment', 'stopwords':'none'})\n",
    "\n",
    "#sentiment all\n",
    "vectorize_and_predict(ocr_counters_sentiment, parameters={'features_used':'sentiment_all', 'stopwords':'none'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_main_row = \"\"\"INSERT INTO main (id, features_used, words_removed, overall_rate, male_match, male_mismatch, \n",
    "female_match, female_mismatch, train_size, test_size, random_seed, test_ids, train_ids) \n",
    "VALUES (null,?,?,?,?,?,?,?,?,?,?,?,?);\"\"\"\n",
    "insert_results_row = \"\"\"INSERT INTO results (id, main_id, from nltk.corpus import sentiwordnet as swnnyt_id, predicted_gender, labeled_gender) \n",
    "VALUES (null,?,?,?,?);\"\"\"\n",
    "insert_coef_row = \"\"\"INSERT INTO coefficients (id, main_id, feature, score, odds) VALUES (null, ?,?,?,?);\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
