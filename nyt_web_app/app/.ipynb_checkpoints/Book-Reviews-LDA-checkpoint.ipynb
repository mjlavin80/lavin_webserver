{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'rb') as handle:\n",
    "    ocr_counters_all = pickle.load(handle)\n",
    "\n",
    "with open('pickled_data/fullstops_pronouns_and_names.pickle', 'rb') as handle5:\n",
    "    fullstops_pronouns_and_names = pickle.load(handle5)\n",
    "\n",
    "with open('pickled_data/nyt_ids_all.pickle', 'rb') as handle3:\n",
    "    nyt_ids_all = pickle.load(handle3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/flask/exthook.py:71: ExtDeprecationWarning: Importing flask.ext.sqlalchemy is deprecated, use flask_sqlalchemy instead.\n",
      "  .format(x=modname), ExtDeprecationWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from application.selective_features import dictionaries_without_features, dictionaries_of_features\n",
    "import pandas as pd\n",
    "\n",
    "ocr_counters_no_stops_pro_names = dictionaries_without_features(ocr_counters_all, fullstops_pronouns_and_names)\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'rb') as handle:\n",
    "    ocr_counters_all = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "v = DictVectorizer()\n",
    "X = v.fit_transform(ocr_counters_no_stops_pro_names)\n",
    "y = TfidfTransformer()\n",
    "Z = y.fit_transform(X)\n",
    "test = Z[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(v.vocabulary_.keys())\n",
    "word_locs = {m: k for k, m in v.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tfidf = []\n",
    "for doc in Z.toarray():\n",
    "    data_tuples = [(word_locs[h], i) for h,i in enumerate(doc)]\n",
    "    topic = pd.DataFrame.from_records(data_tuples, columns=[\"term\", \"score\"])\n",
    "    topic = topic.sort_values(by='score', ascending=False).iloc[:25].reset_index(drop=True)\n",
    "    top_tfidf.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dfs back to lists of dicts\n",
    "top_tfidf_dicts = []\n",
    "for i in top_tfidf:\n",
    "    mydict = dict(list(zip(i['term'], i['score'])))\n",
    "    top_tfidf_dicts.append(mydict)\n",
    "vee = DictVectorizer()\n",
    "EX = vee.fit_transform(top_tfidf_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4fc0471245c1498b0d21b51b\n",
      "4fc045ff45c1498b0d216718\n",
      "4fc0466a45c1498b0d218372\n",
      "4fc0478645c1498b0d21d8dd\n",
      "4fc043f145c1498b0d20d151\n",
      "4fc045fe45c1498b0d216692\n",
      "4fc052b445c1498b0d24eebc\n",
      "4fc051cf45c1498b0d24ad60\n",
      "4fc0471345c1498b0d21b76c\n",
      "4fc0532f45c1498b0d251a14\n"
     ]
    }
   ],
   "source": [
    "garden_results = [(j,k) for j,k in enumerate(top_tfidf) if 'garden' in list(k['term'])]\n",
    "#len(garden_results)\n",
    "for c,d in garden_results:\n",
    "    nyt_id = nyt_ids_all[c]\n",
    "    print(nyt_id)\n",
    "    #d.to_csv(nyt_id+\"_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 50\n",
    "n_top_words = 10\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=25,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=10,\n",
    "                                learning_decay=0.7,\n",
    "                                random_state=11)\n",
    "fit_data = lda.fit_transform(EX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pickled_data/lda_book_reviews.pickle', 'wb') as handle5:\n",
    "    pickle.dump(lda, handle5, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickled_data/fit_data_book_reviews.pickle', 'wb') as handle6:\n",
    "    pickle.dump(fit_data, handle6, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(vee.vocabulary_.keys())\n",
    "word_locs = {m:k for k, m in vee.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for z in lda.components_:\n",
    "    doc = [(word_locs[h], i) for h,i in enumerate(z)]\n",
    "    topic = pd.DataFrame.from_records(doc, columns=[\"term\", \"score\"])\n",
    "    topic = topic.sort_values(by='score', ascending=False).iloc[:10].reset_index(drop=True)\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'african'"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card</td>\n",
       "      <td>1.100899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reverend</td>\n",
       "      <td>0.711764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young</td>\n",
       "      <td>0.657985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strategy</td>\n",
       "      <td>0.638137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mare</td>\n",
       "      <td>0.566368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>foley</td>\n",
       "      <td>0.470888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>delegate</td>\n",
       "      <td>0.455202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>memoir</td>\n",
       "      <td>0.446736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>los</td>\n",
       "      <td>0.406086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>walk</td>\n",
       "      <td>0.374229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term     score\n",
       "0      card  1.100899\n",
       "1  reverend  0.711764\n",
       "2     young  0.657985\n",
       "3  strategy  0.638137\n",
       "4      mare  0.566368\n",
       "5     foley  0.470888\n",
       "6  delegate  0.455202\n",
       "7    memoir  0.446736\n",
       "8       los  0.406086\n",
       "9      walk  0.374229"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'card--reverend--young--strategy--mare--foley--delegate--memoir--los--walk'"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_strings = [\"--\".join(u['term']) for u in topics]\n",
    "topic_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_fits = []\n",
    "for d in fit_data:\n",
    "    topics = [(topic_strings[h], i) for h,i in enumerate(d)]\n",
    "    topicdf = pd.DataFrame.from_records(topics, columns=[\"topic\", \"score\"])\n",
    "    topdf = topicdf.sort_values(by=\"score\", ascending=False).iloc[:5].reset_index(drop=True)\n",
    "    topic_fits.append(topdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_df = pd.DataFrame.from_records([list(f.iloc[0]) for f in topic_fits], columns=[\"topic\", \"fit\"])\n",
    "fits_df.to_csv('lda_50_topics_top_25_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4fc0532945c1498b0d250e4c'"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_ids_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top co-occurrences with 'garden'\n",
    "garden_counters = []\n",
    "for one_counter in ocr_counters_all:\n",
    "    try:\n",
    "        if one_counter['garden'] > 0:\n",
    "            garden_counters.append(one_counter)\n",
    "    except:\n",
    "        pass\n",
    "len(garden_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop counters with garden in them \n",
    "fullstops_pronouns_and_names.extend(['new', 'york', 'time', 'copyright', 'garden'])\n",
    "cocurs = {}\n",
    "for c in garden_counters:\n",
    "    term_list = c.keys()\n",
    "    for term in term_list:\n",
    "        if term not in fullstops_pronouns_and_names:\n",
    "            try:\n",
    "                cocurs[term] += 1\n",
    "            except: \n",
    "                cocurs[term] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cocur_tuples = Counter(cocurs).most_common()\n",
    "df_cocur = pd.DataFrame.from_records(cocur_tuples, columns=[\"term\", \"matches\"])\n",
    "df_cocur.to_csv('garden_co-occurrences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garden_counters_tfidf = []\n",
    "for one_counter_t in top_tfidf_dicts:\n",
    "    try:\n",
    "        if one_counter_t['garden'] > 0:\n",
    "            garden_counters_tfidf.append(one_counter_t)\n",
    "    except:\n",
    "        pass\n",
    "len(garden_counters_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocurs_tfidf = {}\n",
    "for ct in garden_counters_tfidf:\n",
    "    term_list_t = ct.keys()\n",
    "    for term_t in term_list_t:\n",
    "        if term_t not in fullstops_pronouns_and_names:\n",
    "            try:\n",
    "                cocurs_tfidf[term_t] += 1\n",
    "            except: \n",
    "                cocurs_tfidf[term_t] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cocur_tuples_t = Counter(cocurs_tfidf).most_common()\n",
    "df_cocur_t = pd.DataFrame.from_records(cocur_tuples_t, columns=[\"term\", \"matches\"])\n",
    "df_cocur_t.to_csv('garden_co-occurrences_tfidf_cull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
