{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from application import *\n",
    "from application.models import Metadata\n",
    "from  sqlalchemy.sql.expression import func\n",
    "from sqlalchemy.sql import and_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2059"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get single_work reviews\n",
    "single_work = Metadata().query.filter(Metadata.review_type == 'single_focus').order_by(func.rand()).all()\n",
    "len(single_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9882"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get stew of non-review, cluster, brief, multi\n",
    "not_single_work = Metadata().query.filter(Metadata.review_type.in_([\"cluster\", \"really_multi\", \"not_review\", \"brief\"])).order_by(func.rand()).all()\n",
    "len(not_single_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make training, test data and labels\n",
    "trainset = single_work[0:1000] + not_single_work[0:1000]\n",
    "testset = single_work[1000:2000] + not_single_work[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [0 for i in single_work[0:1000]] + [1 for i in not_single_work[0:1000]]\n",
    "test_labels = [0 for i in single_work[1000:2000]] + [1 for i in not_single_work[1000:2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process review text .. one hot encoding\n",
    "trainset_txt = [i.corrected_transcription for i in trainset]\n",
    "testset_txt = [i.corrected_transcription for i in testset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=25,\n",
    "                                   max_features=10000,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(trainset_txt + testset_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tensorflow classifier\n",
    "# score accuracy\n",
    "tfidf = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf[0:2000]\n",
    "tfidf_test = tfidf[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression().fit(tfidf_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(tfidf_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>-2.169950</td>\n",
       "      <td>pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.768857</td>\n",
       "      <td>12mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-0.994396</td>\n",
       "      <td>8vo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7411</th>\n",
       "      <td>-0.914740</td>\n",
       "      <td>tile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>-0.883461</td>\n",
       "      <td>cloth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.833014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>-0.739548</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>-0.712544</td>\n",
       "      <td>labor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>-0.711668</td>\n",
       "      <td>lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6439</th>\n",
       "      <td>-0.696760</td>\n",
       "      <td>says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>-0.679805</td>\n",
       "      <td>did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>-0.666504</td>\n",
       "      <td>things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>-0.661480</td>\n",
       "      <td>ill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>-0.640460</td>\n",
       "      <td>later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4866</th>\n",
       "      <td>-0.622732</td>\n",
       "      <td>nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>-0.595529</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>-0.593129</td>\n",
       "      <td>gentleman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>-0.592690</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>-0.585447</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>-0.581482</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>-0.576062</td>\n",
       "      <td>italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>-0.575738</td>\n",
       "      <td>historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>-0.559256</td>\n",
       "      <td>island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>-0.558974</td>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>-0.541609</td>\n",
       "      <td>ancient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>-0.529930</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>-0.526068</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>-0.520387</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>-0.520187</td>\n",
       "      <td>names</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>-0.517634</td>\n",
       "      <td>chapter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.923768</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5808</th>\n",
       "      <td>0.924932</td>\n",
       "      <td>publishers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>0.938156</td>\n",
       "      <td>season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.941800</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>entitled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>0.949189</td>\n",
       "      <td>messrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>0.961957</td>\n",
       "      <td>edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>0.963448</td>\n",
       "      <td>literary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>0.971918</td>\n",
       "      <td>performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>0.985310</td>\n",
       "      <td>opera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>1.050790</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1.054894</td>\n",
       "      <td>audience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>1.087017</td>\n",
       "      <td>sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>1.106018</td>\n",
       "      <td>issued</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>1.153654</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>1.189030</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>1.324962</td>\n",
       "      <td>library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>1.423532</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>1.458351</td>\n",
       "      <td>views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>1.470020</td>\n",
       "      <td>published</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>1.498853</td>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>1.523370</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>1.574180</td>\n",
       "      <td>week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>1.610979</td>\n",
       "      <td>times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>1.754892</td>\n",
       "      <td>saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>1.825974</td>\n",
       "      <td>readers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>1.976762</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>2.025297</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>3.567301</td>\n",
       "      <td>uncorrected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>3.649371</td>\n",
       "      <td>books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8234 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef         term\n",
       "5584 -2.169950           pp\n",
       "16   -1.768857         12mo\n",
       "88   -0.994396          8vo\n",
       "7411 -0.914740         tile\n",
       "1291 -0.883461        cloth\n",
       "78   -0.833014           50\n",
       "3405 -0.739548      history\n",
       "4093 -0.712544        labor\n",
       "4393 -0.711668         lord\n",
       "6439 -0.696760         says\n",
       "1957 -0.679805          did\n",
       "7341 -0.666504       things\n",
       "3608 -0.661480          ill\n",
       "4145 -0.640460        later\n",
       "4866 -0.622732       nature\n",
       "1034 -0.595529         came\n",
       "3037 -0.593129    gentleman\n",
       "7984 -0.592690        water\n",
       "4331 -0.585447        lived\n",
       "7478 -0.581482         told\n",
       "3924 -0.576062        italy\n",
       "3403 -0.575738   historical\n",
       "3907 -0.559256       island\n",
       "5529 -0.558974    political\n",
       "391  -0.541609      ancient\n",
       "2207 -0.529930        earth\n",
       "3923 -0.526068      italian\n",
       "2663 -0.520387       family\n",
       "4846 -0.520187        names\n",
       "1156 -0.517634      chapter\n",
       "...        ...          ...\n",
       "362   0.923768     american\n",
       "5808  0.924932   publishers\n",
       "6485  0.938156       season\n",
       "33    0.941800         1906\n",
       "2408  0.944444     entitled\n",
       "4662  0.949189       messrs\n",
       "2237  0.961957      edition\n",
       "4326  0.963448     literary\n",
       "5359  0.971918  performance\n",
       "5132  0.985310        opera\n",
       "4826  1.050790        music\n",
       "638   1.054894     audience\n",
       "6406  1.087017         sale\n",
       "3918  1.106018       issued\n",
       "4376  1.153654       london\n",
       "2750  1.189030      fiction\n",
       "4253  1.324962      library\n",
       "4923  1.423532          new\n",
       "7863  1.458351        views\n",
       "5806  1.470020    published\n",
       "6206  1.498853       review\n",
       "5483  1.523370         play\n",
       "8009  1.574180         week\n",
       "7420  1.610979        times\n",
       "6429  1.754892     saturday\n",
       "5942  1.825974      readers\n",
       "4992  1.976762        novel\n",
       "883   2.025297         book\n",
       "7689  3.567301  uncorrected\n",
       "884   3.649371        books\n",
       "\n",
       "[8234 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['coef'] = clf.coef_[0]\n",
    "df['term'] = tfidf_vectorizer.get_feature_names()\n",
    "df = df.sort_values(by=\"coef\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = Metadata().query.filter(Metadata.review_type == 'needs_audit').order_by(func.rand()).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get text\n",
    "unknown_txt = [i.corrected_transcription for i in unknown]\n",
    "# tf_idf\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(trainset_txt + testset_txt)\n",
    "unknown_tfidf = tfidf_vectorizer.transform(unknown_txt)\n",
    "# generate labels, confidence\n",
    "result = clf.predict(unknown_tfidf)\n",
    "#0 is single_work\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultp = clf.predict_proba(unknown_tfidf)\n",
    "#resultp[0]\n",
    "df_unknown = pd.DataFrame(resultp, columns=['single', 'not_single'])\n",
    "df_unknown['nyt_id'] = [i.nyt_id for i in unknown]\n",
    "df_unknown = df_unknown.sort_values(by='not_single')\n",
    "df_unknown.to_csv(\"probably_single.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          136000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 136,289\n",
      "Trainable params: 136,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(8500, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adadelta',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 2s 984us/step - loss: 0.2501 - acc: 0.5000 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 2s 871us/step - loss: 0.2501 - acc: 0.4910 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 2s 792us/step - loss: 0.2502 - acc: 0.4840 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 2s 862us/step - loss: 0.2502 - acc: 0.4890 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 2s 882us/step - loss: 0.2501 - acc: 0.4940 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 2s 831us/step - loss: 0.2502 - acc: 0.4770 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 2s 808us/step - loss: 0.2501 - acc: 0.4870 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 2s 826us/step - loss: 0.2500 - acc: 0.4930 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 2s 830us/step - loss: 0.2500 - acc: 0.5000 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 2s 817us/step - loss: 0.2502 - acc: 0.4890 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 2s 827us/step - loss: 0.2502 - acc: 0.5000 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 2s 834us/step - loss: 0.2501 - acc: 0.4940 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 2s 818us/step - loss: 0.2501 - acc: 0.5000 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 2s 825us/step - loss: 0.2501 - acc: 0.4890 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 2s 802us/step - loss: 0.2501 - acc: 0.4980 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 2s 855us/step - loss: 0.2502 - acc: 0.4900 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 2s 813us/step - loss: 0.2501 - acc: 0.4960 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 2s 814us/step - loss: 0.2500 - acc: 0.4930 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 2s 810us/step - loss: 0.2500 - acc: 0.4940 - val_loss: 0.2500 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 2s 815us/step - loss: 0.2502 - acc: 0.5000 - val_loss: 0.2500 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tfidf_train,\n",
    "                    train_labels,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(tfidf_test, test_labels),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
