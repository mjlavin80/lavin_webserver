{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests \n",
    "import enchant\n",
    "from application import *\n",
    "from application.models import Metadata, Work, Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_rows = pd.read_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in all_rows['nyt_id']:\n",
    "    row = Metadata().query.filter(Metadata.nyt_id == i).one_or_none()\n",
    "    urls.append(row.nyt_pdf_endpoint)                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows['nyt_pdf_endpoint'] = urls\n",
    "all_rows.to_csv(\"/Users/matthewlavin/nyt-reviews-1905-gender/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(703, 159)\n"
     ]
    }
   ],
   "source": [
    "female_rows = all_rows.loc[all_rows['assumed_gender'] == 'f']\n",
    "male_rows = all_rows.loc[all_rows['assumed_gender'] == 'm']\n",
    "\n",
    "print(len(male_rows), len(female_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'all', u'whoever', u'four', u'go', u'mill', u'seemed', u'whose', u'to', u'under', u'very', u'every', u'yourselves', u'did', u'the', u'ten', u'further', u'even', u'what', u'weren', u'above', u'mustn', u'ever', u'thin', u'hasn', u'full', u'never', u'here', u'shouldn', u'others', u'alone', u'along', u'fifteen', u'wherever', u'amount', u'via', u'yourself', u'from', u'would', u'two', u'next', u'few', u'call', u'therefore', u'themselves', u'thru', u'until', u'more', u'becomes', u'hereby', u'herein', u'everywhere', u'must', u'me', u'none', u'ma', u'this', u'anywhere', u'nine', u'can', u'theirs', u'my', u'give', u'something', u'rather', u'six', u'how', u'needn', u'haven', u'may', u'after', u'hereupon', u'such', u'a', u'third', u'whenever', u'so', u'indeed', u'over', u'move', u'through', u'fify', u'still', u'its', u'before', u'thence', u'somewhere', u'll', u'ours', u'might', u'wouldn', u'them', u'someone', u'thereby', u'they', u'not', u'now', u'nor', u'name', u'always', u'didn', u'whither', u'each', u'found', u'side', u'everyone', u'doing', u'eg', u'our', u'beyond', u'out', u'since', u'forty', u're', u'thereupon', u'whereupon', u'besides', u'put', u'anyhow', u'couldn', u'could', u'keep', u'isn', u'ltd', u'hence', u'onto', u'first', u'already', u'seeming', u'thereafter', u'one', u'done', u'another', u'wasn', u'thick', u'twenty', u'top', u'system', u'least', u'anyone', u'their', u'too', u'hundred', u'mostly', u'that', u'nobody', u'part', u'herself', u'than', u'see', u'i', u'were', u'toward', u'and', u'beforehand', u'mine', u'have', u'seem', u'any', u'latter', u'also', u'take', u'which', u'towards', u'though', u'who', u'most', u'eight', u'but', u'nothing', u'why', u'don', u'noone', u'sometimes', u'm', u'amoungst', u'show', u'anyway', u'find', u'hadn', u'behind', u'should', u'only', u'do', u'his', u'get', u'de', u'cannot', u'during', u'him', u'is', u'cry', u'she', u'where', u'namely', u'computer', u'are', u'please', u'enough', u'won', u'between', u'neither', u'across', u'we', u'however', u'both', u'last', u'many', u'whereafter', u'against', u'etc', u's', u'became', u'whole', u'otherwise', u'among', u'co', u'afterwards', u'seems', u'whatever', u'hers', u'moreover', u'throughout', u'three', u'been', u'whom', u'much', u'interest', u'empty', u'fire', u'latterly', u'else', u'former', u'those', u'myself', u'these', u'bill', u'will', u'while', u'ain', u've', u'then', u'almost', u'sincere', u'thus', u'it', u'cant', u'itself', u'in', u'ie', u'if', u'inc', u'perhaps', u'same', u'wherein', u'beside', u'several', u'shan', u'upon', u'off', u'whereby', u'nevertheless', u'well', u'without', u'y', u'meanwhile', u'con', u'yours', u'just', u'less', u'being', u'front', u'yet', u'had', u'except', u'has', u'around', u'five', u'hereafter', u'd', u'either', u'become', u'therein', u'twelve', u'because', u'often', u'some', u'back', u'ourselves', u'for', u'bottom', u'per', u'everything', u'does', u't', u'be', u'nowhere', u'although', u'sixty', u'by', u'on', u'about', u'anything', u'of', u'o', u'whence', u'or', u'own', u'formerly', u'into', u'within', u'due', u'down', u'mightn', u'couldnt', u'your', u'her', u'eleven', u'aren', u'there', u'was', u'himself', u'elsewhere', u'becoming', u'amongst', u'somehow', u'with', u'he', u'made', u'whether', u'up', u'us', u'below', u'un', u'describe', u'am', u'doesn', u'an', u'as', u'sometime', u'at', u'fill', u'again', u'hasnt', u'no', u'whereas', u'when', u'detail', u'other', u'you', u'together', u'serious', u'having', u'once']\n"
     ]
    }
   ],
   "source": [
    "words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words')\n",
    "stoplist1 = words.text.split(\"\\r\\n\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stoplist2 = set(stopwords.words('english'))\n",
    "\n",
    "stoplist1.extend(stoplist2)\n",
    "\n",
    "fullstops = list(set(stoplist1))\n",
    "fullstops = [i for i in fullstops if i !='']\n",
    "\n",
    "def remove_stops(stoplist, wordlist):\n",
    "    result = []\n",
    "    for i in wordlist:\n",
    "        if i not in stoplist:\n",
    "                result.append(i)\n",
    "    return result\n",
    "\n",
    "def spellcheck(wordlist):\n",
    "    result = []\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    for i in wordlist:\n",
    "        if d.check(i) or d.check(i.capitalize()):\n",
    "            result.append(i)\n",
    "         \n",
    "    return result\n",
    "\n",
    "def get_term_tree(list_of_texts, term, nyt_ids_list):\n",
    "    term_list =[]\n",
    "    #normalize ocr errors\n",
    "    for h,i in enumerate(list_of_texts):\n",
    "        #lowercase all\n",
    "        ocr_lower = i.lower()\n",
    "        #tokenize, remove punctuation and numbers, remove tabs, newlines, etc.\n",
    "        ocr_cleaner = ocr_lower.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "        doc = nlp(ocr_cleaner)\n",
    "        ocr_tokens = []\n",
    "        #add to term list any lemma or token that matches term, but not both if they are the same\n",
    "        for token in doc:\n",
    "            ocr_tokens.append(unicode(token))\n",
    "        for z, token in enumerate(doc):\n",
    "            if token.lemma_ == term or unicode(token) == term:\n",
    "                context_list = []\n",
    "                if z >= 6:\n",
    "                    context_list.extend(ocr_tokens[z-6:z-1])\n",
    "                else: \n",
    "                    context_list.extend(ocr_tokens[0:z-1])\n",
    "                \n",
    "                try:\n",
    "                    context_list.extend(ocr_tokens[z:z+7])\n",
    "                except:\n",
    "                    context_list.extend(ocr_tokens[z:[len(ocr_tokens)]])\n",
    "                result = {\"lemma\": token.lemma_, \"token\": unicode(token), \"pos\": token.pos_, \"nyt_id\": nyt_ids_list[h], \n",
    "                          \"context\": context_list}\n",
    "                term_list.append(result)\n",
    "    return term_list\n",
    "            \n",
    "def clean_text(list_of_texts):\n",
    "    fully_cleaned =[]\n",
    "    #normalize ocr errors\n",
    "    for i in list_of_texts:\n",
    "        #lowercase all\n",
    "        ocr_lower = i.lower()\n",
    "        #tokenize, remove punctuation and numbers, remove tabs, newlines, etc.\n",
    "        ocr_cleaner = ocr_lower.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "        doc = nlp(ocr_cleaner)\n",
    "        ocr_tokens = []\n",
    "        for token in doc:\n",
    "            \n",
    "            if token.lemma_ == u'-PRON-' or token.lemma_.isupper():\n",
    "                ocr_tokens.append(unicode(token))\n",
    "            else:\n",
    "                ocr_tokens.append(token.lemma_)\n",
    "        #ocr_tokens = ocr_cleaner.split(\" \")\n",
    "        \n",
    "        no_numbers_or_punct = []\n",
    "        for token in ocr_tokens:\n",
    "            if token.isalpha():\n",
    "                no_numbers_or_punct.append(token)\n",
    "            else:\n",
    "                \n",
    "                new_token = \"\"\n",
    "                for letter in token:\n",
    "                    if letter.isalpha():\n",
    "                        new_token += letter\n",
    "                if new_token != \"\":\n",
    "                    no_numbers_or_punct.append(new_token)  \n",
    "        \n",
    "        \n",
    "        spellchecked = spellcheck(no_numbers_or_punct)\n",
    "        fully_cleaned.append(spellchecked)\n",
    "    return fully_cleaned\n",
    "\n",
    "print(fullstops)\n",
    "\n",
    "#this list of gender terms was generated iteratively by running the logistic regression with all terms, \n",
    "#seeing what correlated the most with gender, and removing words that seemed to have direct gender info in them\n",
    "\n",
    "gender_terms = [\"mr\", \"he\", \"his\", \"him\", \"himself\", \"man\", \"men\", \"boy\", \"boys\", \"manly\", \"masculine\", \"boyish\", \"father\", \\\n",
    "                \"brother\", \"girls\", \"men\", \"women\", \"sisters\", \"daughters\", \"brothers\", \"sons\", \"wife\", \"husband\", \"niece\",\\\n",
    "                \"uncle\", \"nephew\", \"dad\", \"grandfather\", \"son\", \"mrs\", \"miss\", \"her\", \"hers\", \"she\", \"herself\", \"woman\",\\\n",
    "                \"girl\", \"nieces\", \"nephews\", \"fer\", \"mme\", \"mlle\", \\\n",
    "                \"lady\", \"womanly\", \"girlish\", \"girly\", \"mother\", \"daughter\", \"aunt\", \"niece\" \"grandmother\", \"mom\", \"sister\" ]\n",
    "\n",
    "from nltk.corpus import names \n",
    "male = [o.lower() for o in names.words('male.txt')]\n",
    "female = [o.lower() for o in names.words('female.txt')]\n",
    "\n",
    "fullstops_and_pronouns = []\n",
    "\n",
    "for u in [fullstops, gender_terms]:\n",
    "    for i in u:\n",
    "        fullstops_and_pronouns.append(unicode(i))\n",
    "\n",
    "fullstops_and_pronouns = list(set(fullstops_and_pronouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 396, 7982)\n"
     ]
    }
   ],
   "source": [
    "from string import ascii_lowercase\n",
    "fullstops_pronouns_and_names = []\n",
    "\n",
    "for u in [fullstops_and_pronouns, male, female]:\n",
    "    for i in u:\n",
    "        fullstops_pronouns_and_names.append(unicode(i))\n",
    "\n",
    "fullstops_pronouns_and_names.append(unicode(\"thoma\"))\n",
    "\n",
    "for ltr in ascii_lowercase:\n",
    "    fullstops_pronouns_and_names.append(unicode(ltr))\n",
    "\n",
    "fullstops_pronouns_and_names = list(set(fullstops_pronouns_and_names))\n",
    "\n",
    "print(len(fullstops), len(fullstops_and_pronouns), len(fullstops_pronouns_and_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_list_male = []\n",
    "male_nyt_ids = []\n",
    "ocr_list_female = []\n",
    "female_nyt_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in female_rows.iterrows():\n",
    "    row = Metadata().query.filter(Metadata.id == int(i[1][0])).one_or_none()\n",
    "    ocr_list_female.append(row.ocr_transcription)\n",
    "    female_nyt_ids.append(row.nyt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in male_rows.iterrows():\n",
    "    row = Metadata().query.filter(Metadata.id == int(i[1][0])).one_or_none()\n",
    "    ocr_list_male.append(row.ocr_transcription)\n",
    "    male_nyt_ids.append(row.nyt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_for_volume = get_term_tree(ocr_list_male, \"volume\", male_nyt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'4fc047fa45c1498b0d22001a',\n",
       " u'4fc03b9345c1498b0d1e87c6',\n",
       " u'4fc03b9345c1498b0d1e87bd',\n",
       " u'4fc03b9345c1498b0d1e87cb',\n",
       " u'4fc054cf45c1498b0d258c95',\n",
       " u'4fc0528045c1498b0d24e578',\n",
       " u'4fc0532a45c1498b0d250fe9',\n",
       " u'4fc0520845c1498b0d24b887',\n",
       " u'4fc045fe45c1498b0d216556',\n",
       " u'4fc0471145c1498b0d21b379',\n",
       " u'4fc045fe45c1498b0d2165e8',\n",
       " u'4fc0471245c1498b0d21b41e',\n",
       " u'4fc045fe45c1498b0d21664f',\n",
       " u'4fc0466845c1498b0d217f33',\n",
       " u'4fc051cb45c1498b0d24a71e',\n",
       " u'4fc052b245c1498b0d24eacc',\n",
       " u'4fc03a7c45c1498b0d1e2d1b',\n",
       " u'4fc0466845c1498b0d217f48',\n",
       " u'4fc0451845c1498b0d2122a4',\n",
       " u'4fc0466845c1498b0d217fe1',\n",
       " u'4fc052b245c1498b0d24eb40',\n",
       " u'4fc051cb45c1498b0d24a792',\n",
       " u'4fc0466945c1498b0d218089',\n",
       " u'4fc0451845c1498b0d2122c5',\n",
       " u'4fc0466945c1498b0d21807d',\n",
       " u'4fc051cb45c1498b0d24a7da',\n",
       " u'4fc03a7d45c1498b0d1e2dab',\n",
       " u'4fc0466945c1498b0d218080',\n",
       " u'4fc03a7d45c1498b0d1e2daf',\n",
       " u'4fc051cb45c1498b0d24a7ed',\n",
       " u'4fc0478545c1498b0d21d6e8',\n",
       " u'4fc043f045c1498b0d20cfa3',\n",
       " u'4fc0478545c1498b0d21d6f5',\n",
       " u'4fc039f645c1498b0d1e138e',\n",
       " u'4fc03a7d45c1498b0d1e2e2c',\n",
       " u'4fc043f045c1498b0d20cfa8',\n",
       " u'4fc052b345c1498b0d24ec4d',\n",
       " u'4fc04ef245c1498b0d23e643',\n",
       " u'4fc04ef345c1498b0d23e6c1',\n",
       " u'4fc0478645c1498b0d21d7a8',\n",
       " u'4fc0478645c1498b0d21d7ad',\n",
       " u'4fc04ef345c1498b0d23e708',\n",
       " u'4fc0478645c1498b0d21d84a',\n",
       " u'4fc0451845c1498b0d212320',\n",
       " u'4fc0478645c1498b0d21d82b',\n",
       " u'4fc043f145c1498b0d20d0d3',\n",
       " u'4fc039f645c1498b0d1e143d',\n",
       " u'4fc03a7d45c1498b0d1e2e6e',\n",
       " u'4fc039f645c1498b0d1e1498',\n",
       " u'4fc0515445c1498b0d248fa7',\n",
       " u'4fc0478645c1498b0d21d8dd',\n",
       " u'4fc0478645c1498b0d21d8f1',\n",
       " u'4fc04ef345c1498b0d23e76e',\n",
       " u'4fc0478645c1498b0d21d8da',\n",
       " u'4fc043f145c1498b0d20d151',\n",
       " u'4fc039f645c1498b0d1e1509',\n",
       " u'4fc043f145c1498b0d20d1eb',\n",
       " u'4fc0478745c1498b0d21d9bd',\n",
       " u'4fc043f145c1498b0d20d1ea',\n",
       " u'4fc0478745c1498b0d21d9b5',\n",
       " u'4fc043f145c1498b0d20d1e0',\n",
       " u'4fc0478745c1498b0d21d9a7',\n",
       " u'4fc052b345c1498b0d24ed2e',\n",
       " u'4fc045fe45c1498b0d216693',\n",
       " u'4fc045fe45c1498b0d216692',\n",
       " u'4fc0454e45c1498b0d212d40',\n",
       " u'4fc0454e45c1498b0d212d35',\n",
       " u'4fc0499f45c1498b0d226f38',\n",
       " u'4fc03b9445c1498b0d1e8a37',\n",
       " u'4fc048a345c1498b0d2227ac',\n",
       " u'4fc0454e45c1498b0d212da4',\n",
       " u'4fc0499f45c1498b0d226f3c',\n",
       " u'4fc0471245c1498b0d21b577',\n",
       " u'4fc0454f45c1498b0d212e17',\n",
       " u'4fc0520a45c1498b0d24bb58',\n",
       " u'4fc0520a45c1498b0d24bc15',\n",
       " u'4fc0454f45c1498b0d212e8b',\n",
       " u'4fc0532b45c1498b0d2511fe',\n",
       " u'4fc0454f45c1498b0d212efd',\n",
       " u'4fc0455145c1498b0d212f8a',\n",
       " u'4fc049a045c1498b0d2270a7',\n",
       " u'4fc049a045c1498b0d2270ad',\n",
       " u'4fc049a045c1498b0d2270b3',\n",
       " u'4fc0532b45c1498b0d251235',\n",
       " u'4fc0520b45c1498b0d24bda4',\n",
       " u'4fc0520b45c1498b0d24be49',\n",
       " u'4fc049a045c1498b0d227106',\n",
       " u'4fc049a045c1498b0d227100',\n",
       " u'4fc0471345c1498b0d21b67b',\n",
       " u'4fc048a445c1498b0d2229ae',\n",
       " u'4fc0455345c1498b0d21308d',\n",
       " u'4fc048a445c1498b0d2229a9',\n",
       " u'4fc0520c45c1498b0d24beef',\n",
       " u'4fc03a7d45c1498b0d1e2e9c',\n",
       " u'4fc03a7d45c1498b0d1e2ebb',\n",
       " u'4fc0466a45c1498b0d2181d8',\n",
       " u'4fc052b345c1498b0d24ed54',\n",
       " u'4fc048a845c1498b0d22312b',\n",
       " u'4fc03a8445c1498b0d1e3c03',\n",
       " u'4fc0451845c1498b0d2123bb',\n",
       " u'4fc0451845c1498b0d2123c1',\n",
       " u'4fc052b445c1498b0d24ee3b',\n",
       " u'4fc0466a45c1498b0d2182a7',\n",
       " u'4fc052b445c1498b0d24eebc',\n",
       " u'4fc048a545c1498b0d222af0',\n",
       " u'4fc03a7e45c1498b0d1e3120',\n",
       " u'4fc03a7e45c1498b0d1e31b7',\n",
       " u'4fc03a8345c1498b0d1e3a5d',\n",
       " u'4fc03a7f45c1498b0d1e3267',\n",
       " u'4fc0466f45c1498b0d218b93',\n",
       " u'4fc052b545c1498b0d24efa0',\n",
       " u'4fc051cf45c1498b0d24acb6',\n",
       " u'4fc052ba45c1498b0d24f879',\n",
       " u'4fc052b545c1498b0d24f0f0',\n",
       " u'4fc051d545c1498b0d24b5b6',\n",
       " u'4fc051cf45c1498b0d24ad60',\n",
       " u'4fc03a8045c1498b0d1e3539',\n",
       " u'4fc043f645c1498b0d20d79e',\n",
       " u'4fc043f745c1498b0d20d879',\n",
       " u'4fc03a8145c1498b0d1e3631',\n",
       " u'4fc03a8145c1498b0d1e362a',\n",
       " u'4fc0451a45c1498b0d21266e',\n",
       " u'4fc051d545c1498b0d24b53d',\n",
       " u'4fc051d045c1498b0d24af27',\n",
       " u'4fc051d045c1498b0d24af26',\n",
       " u'4fc03a8245c1498b0d1e3839',\n",
       " u'4fc052b845c1498b0d24f509',\n",
       " u'4fc052b845c1498b0d24f519',\n",
       " u'4fc03a8245c1498b0d1e3820',\n",
       " u'4fc043f645c1498b0d20d736',\n",
       " u'4fc048a545c1498b0d222c80',\n",
       " u'4fc0466c45c1498b0d2186fe',\n",
       " u'4fc0466f45c1498b0d218b88',\n",
       " u'4fc0466c45c1498b0d2187a5',\n",
       " u'4fc0532c45c1498b0d2513ba',\n",
       " u'4fc048a645c1498b0d222d0e',\n",
       " u'4fc048a645c1498b0d222d06',\n",
       " u'4fc0471345c1498b0d21b76c',\n",
       " u'4fc052b845c1498b0d24f5a1',\n",
       " u'4fc048a645c1498b0d222de4',\n",
       " u'4fc0532c45c1498b0d25148e',\n",
       " u'4fc0455845c1498b0d213967',\n",
       " u'4fc0466d45c1498b0d2188cc',\n",
       " u'4fc0532c45c1498b0d251495',\n",
       " u'4fc03b9445c1498b0d1e8b43',\n",
       " u'4fc045ff45c1498b0d2167de',\n",
       " u'4fc0520f45c1498b0d24c33f',\n",
       " u'4fc045ff45c1498b0d216862',\n",
       " u'4fc0520d45c1498b0d24c0f4',\n",
       " u'4fc0532f45c1498b0d251a14',\n",
       " u'4fc0520d45c1498b0d24c163',\n",
       " u'4fc0532d45c1498b0d251693',\n",
       " u'4fc0471545c1498b0d21bac3',\n",
       " u'4fc03b9545c1498b0d1e8caf',\n",
       " u'4fc0528045c1498b0d24e6a4',\n",
       " u'4fc0520e45c1498b0d24c261',\n",
       " u'4fc0532e45c1498b0d2517e1',\n",
       " u'4fc0455745c1498b0d2136a5',\n",
       " u'4fc051d345c1498b0d24b399']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_nyt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_for_garden = get_term_tree(ocr_list_female, \"garden\", female_nyt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_for_gardener = get_term_tree(ocr_list_female, \"gardener\", female_nyt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set([u['nyt_id'] for u in tree_for_garden])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>lemma</th>\n",
       "      <th>nyt_id</th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[their, ., houses, or, digs, gardens, than, to...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc045fe45c1498b0d216556</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[its, first, chapter, entitled, \", garden, of,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc045fe45c1498b0d2165e8</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pluce, been, converted, into, a, garden, ?, t...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0466945c1498b0d218080</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[in, a, qiilet, corner, .of, garden, in, the, ...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc03a7d45c1498b0d1e2e2c</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[holds, the, key, to, some, garden, of, the, i...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0478645c1498b0d21d8dd</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[the, \", littlt, palace, of, garden, ,, ”, the...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0478645c1498b0d21d8dd</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[charms, of, the, apple, in, garden, of, eden,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc043f145c1498b0d20d151</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[house, alone, ,, working, in, garden, ,, dugt...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc043f145c1498b0d20d151</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[﻿thk, garden, ., by, tvllla, slbort, cather, .]</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc045fe45c1498b0d216692</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[fairy, palace, ., with, a, garden, ;, •, •, *...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc045fe45c1498b0d216692</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[there, is, something, about, “, garden, lodge...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc045fe45c1498b0d216692</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[,, landed, as, immigrants, at, garden, their,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc049a045c1498b0d227106</td>\n",
       "      <td>VERB</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[barbara, ,, author, of, \", garden, of, &amp;, com...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24ee3b</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[a, becoming, background, out, of, gardens, an...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[literary, \\r , listener, ., \\r , gardens, the...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[the, earth, ., they, are, gardens, in, jersey...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[in, jersey, ,, ot, *, gardens, ,, or, italian...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[*, german, gardens, ,, or, gardens, ,, or, ja...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-, dens, ,, or, plain, gardens, ,, or, they, ...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[kitchen, gardens, ,, or, they, gardens, of, t...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[book, is, all, about, an, garden, in, the, tr...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[opposite, neighbor, who, likewise, owned, gar...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[call, theirs, “, plebe.'’, \\r , garden, in, t...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[•my, garden, in, the, city, gardens, ., a, me...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc052b445c1498b0d24eebc</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[hosts, the, yellow, moon, over, gardens, fill...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0466f45c1498b0d218b93</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[of, the, orient, in, his, garden, ,, and, hea...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0466f45c1498b0d218b93</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[author, of, *, ', judith, garden, ., \", illus...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc051cf45c1498b0d24ad60</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[louis, of, prance, had, a, garden, sot, apart...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc051cf45c1498b0d24ad60</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[by, him, ., and, into, garden, came, a, maid,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc051cf45c1498b0d24ad60</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[day, the, king, did, enter, garden, and, saw,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc051cf45c1498b0d24ad60</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[., -, *, \\r , while, garden, air, thus, is, h...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc051cf45c1498b0d24ad60</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[st, ., mar, leaps, into, garden, and, makes, ...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc051cf45c1498b0d24ad60</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[him, a, house, and, therewith, garden, at, wa...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0451a45c1498b0d21266e</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[\\r , stroll, in, my, fair, garden, hap, ;, pi...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0466c45c1498b0d2186fe</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[she, insisted, upon, going, into, garden, may...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0471345c1498b0d21b76c</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[fancy, ., the, scene, in, garden, at, midnigh...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0471345c1498b0d21b76c</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[italian, ., villas, anfl, tfieir, gardens, ,,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0532f45c1498b0d251a14</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[these, villas, and, palaces, and, gardens, ,,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0532f45c1498b0d251a14</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[the, famous, homan, villas, and, gardens, fir...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0532f45c1498b0d251a14</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[then, come, the, famous, villas, gardens, of,...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0532f45c1498b0d251a14</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[which, are, devoted, to, the, gardens, repres...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0532f45c1498b0d251a14</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[conditions, which, produced, these, palaces, ...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0532f45c1498b0d251a14</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[own, inimitable, way, of, the, garden, and, t...</td>\n",
       "      <td>garden</td>\n",
       "      <td>4fc0471545c1498b0d21bac3</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>garden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              context   lemma  \\\n",
       "0   [their, ., houses, or, digs, gardens, than, to...  garden   \n",
       "1   [its, first, chapter, entitled, \", garden, of,...  garden   \n",
       "2   [pluce, been, converted, into, a, garden, ?, t...  garden   \n",
       "3   [in, a, qiilet, corner, .of, garden, in, the, ...  garden   \n",
       "4   [holds, the, key, to, some, garden, of, the, i...  garden   \n",
       "5   [the, \", littlt, palace, of, garden, ,, ”, the...  garden   \n",
       "6   [charms, of, the, apple, in, garden, of, eden,...  garden   \n",
       "7   [house, alone, ,, working, in, garden, ,, dugt...  garden   \n",
       "8    [﻿thk, garden, ., by, tvllla, slbort, cather, .]  garden   \n",
       "9   [fairy, palace, ., with, a, garden, ;, •, •, *...  garden   \n",
       "10  [there, is, something, about, “, garden, lodge...  garden   \n",
       "11  [,, landed, as, immigrants, at, garden, their,...  garden   \n",
       "12  [barbara, ,, author, of, \", garden, of, &, com...  garden   \n",
       "13  [a, becoming, background, out, of, gardens, an...  garden   \n",
       "14  [literary, \\r , listener, ., \\r , gardens, the...  garden   \n",
       "15  [the, earth, ., they, are, gardens, in, jersey...  garden   \n",
       "16  [in, jersey, ,, ot, *, gardens, ,, or, italian...  garden   \n",
       "17  [*, german, gardens, ,, or, gardens, ,, or, ja...  garden   \n",
       "18  [-, dens, ,, or, plain, gardens, ,, or, they, ...  garden   \n",
       "19  [kitchen, gardens, ,, or, they, gardens, of, t...  garden   \n",
       "20  [book, is, all, about, an, garden, in, the, tr...  garden   \n",
       "21  [opposite, neighbor, who, likewise, owned, gar...  garden   \n",
       "22  [call, theirs, “, plebe.'’, \\r , garden, in, t...  garden   \n",
       "23  [•my, garden, in, the, city, gardens, ., a, me...  garden   \n",
       "24  [hosts, the, yellow, moon, over, gardens, fill...  garden   \n",
       "25  [of, the, orient, in, his, garden, ,, and, hea...  garden   \n",
       "26  [author, of, *, ', judith, garden, ., \", illus...  garden   \n",
       "27  [louis, of, prance, had, a, garden, sot, apart...  garden   \n",
       "28  [by, him, ., and, into, garden, came, a, maid,...  garden   \n",
       "29  [day, the, king, did, enter, garden, and, saw,...  garden   \n",
       "30  [., -, *, \\r , while, garden, air, thus, is, h...  garden   \n",
       "31  [st, ., mar, leaps, into, garden, and, makes, ...  garden   \n",
       "32  [him, a, house, and, therewith, garden, at, wa...  garden   \n",
       "33  [\\r , stroll, in, my, fair, garden, hap, ;, pi...  garden   \n",
       "34  [she, insisted, upon, going, into, garden, may...  garden   \n",
       "35  [fancy, ., the, scene, in, garden, at, midnigh...  garden   \n",
       "36  [italian, ., villas, anfl, tfieir, gardens, ,,...  garden   \n",
       "37  [these, villas, and, palaces, and, gardens, ,,...  garden   \n",
       "38  [the, famous, homan, villas, and, gardens, fir...  garden   \n",
       "39  [then, come, the, famous, villas, gardens, of,...  garden   \n",
       "40  [which, are, devoted, to, the, gardens, repres...  garden   \n",
       "41  [conditions, which, produced, these, palaces, ...  garden   \n",
       "42  [own, inimitable, way, of, the, garden, and, t...  garden   \n",
       "\n",
       "                      nyt_id   pos    token  \n",
       "0   4fc045fe45c1498b0d216556  NOUN  gardens  \n",
       "1   4fc045fe45c1498b0d2165e8  NOUN   garden  \n",
       "2   4fc0466945c1498b0d218080  NOUN   garden  \n",
       "3   4fc03a7d45c1498b0d1e2e2c  NOUN   garden  \n",
       "4   4fc0478645c1498b0d21d8dd  NOUN   garden  \n",
       "5   4fc0478645c1498b0d21d8dd  NOUN   garden  \n",
       "6   4fc043f145c1498b0d20d151  NOUN   garden  \n",
       "7   4fc043f145c1498b0d20d151  NOUN   garden  \n",
       "8   4fc045fe45c1498b0d216692  NOUN   garden  \n",
       "9   4fc045fe45c1498b0d216692  NOUN   garden  \n",
       "10  4fc045fe45c1498b0d216692  NOUN   garden  \n",
       "11  4fc049a045c1498b0d227106  VERB   garden  \n",
       "12  4fc052b445c1498b0d24ee3b  NOUN   garden  \n",
       "13  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "14  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "15  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "16  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "17  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "18  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "19  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "20  4fc052b445c1498b0d24eebc  NOUN   garden  \n",
       "21  4fc052b445c1498b0d24eebc  NOUN   garden  \n",
       "22  4fc052b445c1498b0d24eebc  NOUN   garden  \n",
       "23  4fc052b445c1498b0d24eebc  NOUN  gardens  \n",
       "24  4fc0466f45c1498b0d218b93  NOUN  gardens  \n",
       "25  4fc0466f45c1498b0d218b93  NOUN   garden  \n",
       "26  4fc051cf45c1498b0d24ad60  NOUN   garden  \n",
       "27  4fc051cf45c1498b0d24ad60  NOUN   garden  \n",
       "28  4fc051cf45c1498b0d24ad60  NOUN   garden  \n",
       "29  4fc051cf45c1498b0d24ad60  NOUN   garden  \n",
       "30  4fc051cf45c1498b0d24ad60  NOUN   garden  \n",
       "31  4fc051cf45c1498b0d24ad60  NOUN   garden  \n",
       "32  4fc0451a45c1498b0d21266e  NOUN   garden  \n",
       "33  4fc0466c45c1498b0d2186fe  NOUN   garden  \n",
       "34  4fc0471345c1498b0d21b76c  NOUN   garden  \n",
       "35  4fc0471345c1498b0d21b76c  NOUN   garden  \n",
       "36  4fc0532f45c1498b0d251a14  NOUN  gardens  \n",
       "37  4fc0532f45c1498b0d251a14  NOUN  gardens  \n",
       "38  4fc0532f45c1498b0d251a14  NOUN  gardens  \n",
       "39  4fc0532f45c1498b0d251a14  NOUN  gardens  \n",
       "40  4fc0532f45c1498b0d251a14  NOUN  gardens  \n",
       "41  4fc0532f45c1498b0d251a14  NOUN  gardens  \n",
       "42  4fc0471545c1498b0d21bac3  NOUN   garden  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tree_for_garden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for a in wn.synsets('garden'):\n",
    "    print(a.definition())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_cleaned_male = clean_text(ocr_list_male)\n",
    "ocr_cleaned_female = clean_text(ocr_list_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "ocr_counters_male = [Counter(i) for i in ocr_cleaned_male]\n",
    "ocr_counters_female = [Counter(i) for i in ocr_cleaned_female]\n",
    "ocr_counters_all = []\n",
    "for i in ocr_counters_male:\n",
    "    ocr_counters_all.append(i)\n",
    "for i in ocr_counters_female:\n",
    "    ocr_counters_all.append(i)\n",
    "nyt_ids_all = []\n",
    "for i in male_nyt_ids:\n",
    "    nyt_ids_all.append(i)\n",
    "for i in female_nyt_ids:\n",
    "    nyt_ids_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h,i in enumerate(nyt_ids_all):\n",
    "    filename = \"\".join([\"/Users/matthewlavin/nyt-reviews-1905-gender/lemma-data/\", i, \".csv\"])\n",
    "    df = pd.DataFrame.from_records(ocr_counters_all[h].items(), columns=['lemma', 'count']).sort_values(by=\"count\", ascending=False)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pickled_data/ocr_counters_all.pickle', 'wb') as handle:\n",
    "    pickle.dump(ocr_counters_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickled_data/nyt_ids_all.pickle', 'wb') as handle3:\n",
    "    pickle.dump(nyt_ids_all, handle3, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_data/fullstops.pickle', 'wb') as handle2:\n",
    "    pickle.dump(fullstops, handle2, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickled_data/fullstops_and_pronouns.pickle', 'wb') as handle4:\n",
    "    pickle.dump(fullstops_and_pronouns, handle4, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickled_data/fullstops_pronouns_and_names.pickle', 'wb') as handle5:\n",
    "    pickle.dump(fullstops_pronouns_and_names, handle5, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrc_rows = pd.read_csv(\"lexicons/NRC-emotion-lexicon.txt\", sep=\"\\t\", header=None, names=[\"term\", \"valence\", \"score\"])\n",
    "nrc_rows_positive = nrc_rows.loc[(nrc_rows['score'] == 1) & (nrc_rows['valence'] == 'positive')]\n",
    "nrc_rows_negative = nrc_rows.loc[(nrc_rows['score'] == 1) & (nrc_rows['valence'] == 'negative')]\n",
    "\n",
    "pos_terms = list(nrc_rows_positive['term'])\n",
    "neg_terms = list(nrc_rows_negative['term'])\n",
    "\n",
    "def remove_dupes(source, target):\n",
    "    unique = []\n",
    "    for s in source: \n",
    "        if s not in target:\n",
    "            unique.append(s)\n",
    "    return unique\n",
    "\n",
    "pos_terms_unique = remove_dupes(pos_terms, neg_terms)\n",
    "neg_terms_unique = remove_dupes(neg_terms, pos_terms)\n",
    "\n",
    "with open('pickled_data/nrc_positive.pickle', 'wb') as handle6:\n",
    "    pickle.dump(pos_terms_unique, handle6, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('pickled_data/nrc_negative.pickle', 'wb') as handle7:\n",
    "    pickle.dump(neg_terms_unique, handle7, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(nrc_rows_negative['term']) + list(nrc_rows_positive['term']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"he\" == unicode(\"he\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = enchant.Dict(\"en_US\")\n",
    "d.check(\"Thoma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
